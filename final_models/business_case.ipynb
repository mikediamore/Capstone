{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of focusing on market events, I moved on to the fluctuation of S&P500 index. If we can predict whether it will increase or decrease the next day, we can make investments out of it. Here I did a long-short on SPY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline\n",
    "* Keras Model for predicting ups and downs\n",
    "* Calculating profit using long-short strategy\n",
    "* DeepLIFT for predicting model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and perpare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# np.random.seed(12345) # Set seed\n",
    "\n",
    "# import Query as query\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTEENN \n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import resample\n",
    "from keras.layers import Dense,BatchNormalization,Input,Convolution1D,GRU,Dropout\n",
    "#from keras.models import Model\n",
    "import keras\n",
    "#import pdb\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,recall_score,precision_score\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import deeplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collapsed_shifted = pd.read_csv('collapsed_shifted.csv',index_col=0)\n",
    "#event_idx = pd.read_csv('event_idx.csv',header=None,index_col=0)\n",
    "#event_idx = np.array(event_idx).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling the days with increasing S&P500 index price with 1 and decreasing with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff = collapsed_shifted['Adj Close'].diff()\n",
    "diff[diff>0]=1\n",
    "diff[diff<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.array(diff).astype(int).flatten()\n",
    "labels = pd.Series(labels,index=collapsed_shifted.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_idx = labels.drop(['2000-07-03'])\n",
    "collapsed_shifted = collapsed_shifted.drop(['2000-07-03'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train test split...\n"
     ]
    }
   ],
   "source": [
    "print ('Creating train test split...')\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(collapsed_shifted,event_idx,stratify=None,test_size=.20,shuffle=False)\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(X_train,Y_train,test_size=.20,stratify=None,shuffle=False)\n",
    "\n",
    "#Creating Copies of Data Frames these will be useful later for debugging\n",
    "X_train_df = X_train.copy(True)\n",
    "Y_train_df = Y_train.copy(True)\n",
    "Y_val_df = Y_val.copy(True)\n",
    "X_train  = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,X_train.shape[1],1)\n",
    "X_test = X_test.reshape(-1,X_test.shape[1],1)\n",
    "X_val = X_val.reshape(-1,X_val.shape[1],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.regularizers import l1l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import MaxoutDense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling1D\n",
    "\n",
    "def simple_keras_model(original):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(128, 5, border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5),input_shape =(original.shape[1],1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D())\n",
    "    #model.add(Dropout(.55))\n",
    "    #model.add(Convolution1D(512,5,border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5)))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(MaxPooling1D())\n",
    "    #model.add(Dropout(.55))\n",
    "    #model.add(Convolution1D(256,5,border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5)))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(.55))\n",
    "    #model.add(Convolution1D(128,5,border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5)))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(.55))\n",
    "    #model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(.35))\n",
    "    #model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(.35))\n",
    "    #model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(.35))\n",
    "    #model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(.35))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(1024,activation='relu',init='he_normal'))\n",
    "    #model.add(Dense(512,activation='relu',init='he_normal'))\n",
    "    model.add(Dense(64,activation='relu',init='he_normal'))\n",
    "    #model.add(Dropout(0.35))\n",
    "    \n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    \n",
    "    \n",
    "    #my_model = Model([original_input], output=output)\n",
    "    optimizer_adam = keras.optimizers.adam(0.001) \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer_adam, metrics=['accuracy'])\n",
    "\n",
    "    return(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = keras.utils.np_utils.to_categorical(nb_classes=2,y=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2779/2779 [==============================] - 3s - loss: 0.7476 - acc: 0.5916     \n",
      "Epoch 2/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.4941 - acc: 0.7632     \n",
      "Epoch 3/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.3960 - acc: 0.8276     \n",
      "Epoch 4/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.3376 - acc: 0.8550     \n",
      "Epoch 5/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.2996 - acc: 0.8744     \n",
      "Epoch 6/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.2587 - acc: 0.8942     \n",
      "Epoch 7/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.2226 - acc: 0.9169     \n",
      "Epoch 8/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.2216 - acc: 0.9108     \n",
      "Epoch 9/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.2068 - acc: 0.9187     \n",
      "Epoch 10/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.1834 - acc: 0.9298     \n",
      "Epoch 11/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.1882 - acc: 0.9252     \n",
      "Epoch 12/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.1910 - acc: 0.9280     \n",
      "Epoch 13/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.1880 - acc: 0.9208     \n",
      "Epoch 14/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.1599 - acc: 0.9421     \n",
      "Epoch 15/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.1499 - acc: 0.9424     \n",
      "Epoch 16/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.1465 - acc: 0.9449     \n",
      "Epoch 17/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.1198 - acc: 0.9687     \n",
      "Epoch 18/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.1053 - acc: 0.9683     \n",
      "Epoch 19/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.1022 - acc: 0.9705     \n",
      "Epoch 20/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0964 - acc: 0.9741     \n",
      "Epoch 21/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.1040 - acc: 0.9676     \n",
      "Epoch 22/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.1118 - acc: 0.9604     \n",
      "Epoch 23/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0896 - acc: 0.9737     \n",
      "Epoch 24/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0987 - acc: 0.9694     \n",
      "Epoch 25/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0847 - acc: 0.9730     \n",
      "Epoch 26/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0805 - acc: 0.9759     \n",
      "Epoch 27/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0698 - acc: 0.9802     \n",
      "Epoch 28/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0786 - acc: 0.9752     \n",
      "Epoch 29/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0780 - acc: 0.9734     \n",
      "Epoch 30/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.1043 - acc: 0.9597     \n",
      "Epoch 31/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0643 - acc: 0.9838     \n",
      "Epoch 32/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0629 - acc: 0.9827     \n",
      "Epoch 33/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0560 - acc: 0.9870     - ETA: 0s - loss: 0.0545 - acc\n",
      "Epoch 34/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0469 - acc: 0.9910     \n",
      "Epoch 35/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0475 - acc: 0.9906     \n",
      "Epoch 36/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0616 - acc: 0.9809     \n",
      "Epoch 37/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0523 - acc: 0.9874     \n",
      "Epoch 38/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0462 - acc: 0.9881     \n",
      "Epoch 39/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0384 - acc: 0.9939     \n",
      "Epoch 40/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0404 - acc: 0.9910     \n",
      "Epoch 41/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0377 - acc: 0.9935     \n",
      "Epoch 42/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0362 - acc: 0.9921     - ETA: 0s - loss: 0.0358 - acc: \n",
      "Epoch 43/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0348 - acc: 0.9928     \n",
      "Epoch 44/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0343 - acc: 0.9935     \n",
      "Epoch 45/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0446 - acc: 0.9881     \n",
      "Epoch 46/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0569 - acc: 0.9809     \n",
      "Epoch 47/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0556 - acc: 0.9798     \n",
      "Epoch 48/50\n",
      "2779/2779 [==============================] - 0s - loss: 0.0447 - acc: 0.9878     \n",
      "Epoch 49/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0339 - acc: 0.9924     \n",
      "Epoch 50/50\n",
      "2779/2779 [==============================] - 1s - loss: 0.0278 - acc: 0.9953     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a49f74f60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "my_model = simple_keras_model(X_train)\n",
    "my_model.fit(X_train,Y_train,nb_epoch=50 ,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_to_label(pred):\n",
    "    ones = np.argmax(pred,1)\n",
    "    return(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas = my_model.predict(X_val)\n",
    "preds = softmax_to_label(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " On Validation Set\n",
      " Accuracy: 0.8776978417266187\n",
      " F1: 0.883720930232558\n",
      " RoC: 0.8781159420289856\n",
      " Precision: 0.8367875647668394\n",
      " Recall: 0.936231884057971\n",
      " Area under PR curve 0.9023370625419016\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(Y_val,preds)\n",
    "f1 = f1_score(Y_val,preds)\n",
    "roc = roc_auc_score(Y_val,preds)\n",
    "prec = precision_score(Y_val,preds)\n",
    "recall2= recall_score(Y_val,preds)\n",
    "\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(Y_val,preds)\n",
    "avg_prec = average_precision_score(Y_val,preds)\n",
    "area_under_prec_rec = auc(x=recall,y=precision)\n",
    "\n",
    "print (' On Validation Set')\n",
    "print (' Accuracy: {}'.format(acc))\n",
    "print (' F1: {}'.format(f1))\n",
    "print (' RoC: {}'.format(roc))\n",
    "print (' Precision: {}'.format(prec))\n",
    "print (' Recall: {}'.format(recall2))\n",
    "print (' Area under PR curve {}'.format(area_under_prec_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take into business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use long-short strategy with predicted ups and downs for SPY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['Truth'] = pd.Series(Y_val.values, index=Y_val.index)\n",
    "results['Pred'] = pd.Series(preds, index=results.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPY = pd.read_csv('SPY.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_day = SPY['Adj Close']\n",
    "previous_day = SPY['Adj Close'].shift(1)\n",
    "rate = (next_day-previous_day)/previous_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['rate'] = pd.Series(rate.loc[results.index], index=results.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = results.index[results['Pred']==1]\n",
    "down = results.index[results['Pred']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results['long_profit'] = results['rate'].loc[up]+1\n",
    "results['short_profit'] = results['rate'].loc[down].abs()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['profit'] = results[[\"long_profit\", \"short_profit\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The profit would be more than 12 times of the beginning investment, excluding the commissions and other costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.817001591897178"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(results['profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeplift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also did deeplift for this model. Similarly, Gdelt features are getting the lowest importance scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted from the code provided by the authors of the paper [https://arxiv.org/abs/1704.02685]:\n",
    "https://github.com/kundajelab/deeplift/blob/tensorflow/deeplift/conversion/keras_conversion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No reference provided - using zeros\n",
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n"
     ]
    }
   ],
   "source": [
    "#Convert a keras sequential model\n",
    "import deeplift\n",
    "from deeplift.conversion import keras_conversion as kc\n",
    "#MxtsMode defines the method for computing importance scores. Other supported values are:\n",
    "#Gradient, DeconvNet, GuidedBackprop and GuidedBackpropDeepLIFT (a hybrid of GuidedBackprop and DeepLIFT where\n",
    "#negative multipliers are ignored during backpropagation)\n",
    "deeplift_model = kc.convert_sequential_model(\n",
    "                    my_model,\n",
    "                    nonlinear_mxts_mode=deeplift.blobs.NonlinearMxtsMode.DeepLIFT)\n",
    "\n",
    "#Specify the index of the layer to compute the importance scores of.\n",
    "#In the example below, we find scores for the input layer, which is idx 0 in deeplift_model.get_layers()\n",
    "find_scores_layer_idx = 0\n",
    "\n",
    "#Compile the function that computes the importance scores\n",
    "#For sigmoid or softmax outputs, target_layer_idx should be -2 (the default)\n",
    "#(See \"a note on final activation layers\" in https://arxiv.org/pdf/1605.01713v2.pdf for justification)\n",
    "#For regression tasks with a linear output, target_layer_idx should be -1\n",
    "#(which simply refers to the last layer)\n",
    "#FYI: In the case of MxtsMode.DeepLIFT, the importance scores are also called \"contribution scores\"\n",
    "#If you want the multipliers instead of the contribution scores, you can use get_target_multipliers_func\n",
    "deeplift_contribs_func = deeplift_model.get_target_contribs_func(\n",
    "                            find_scores_layer_idx=find_scores_layer_idx,\n",
    "                            target_layer_idx=-2)\n",
    "\n",
    "#compute scores on inputs\n",
    "#input_data_list is a list containing the data for different input layers\n",
    "#eg: for MNIST, there is one input layer with with dimensions 1 x 28 x 28\n",
    "#In the example below, let X be an array with dimension n x 1 x 28 x 28 where n is the number of examples\n",
    "#task_idx represents the index of the node in the output layer that we wish to compute scores.\n",
    "#Eg: if the output is a 10-way softmax, and task_idx is 0, we will compute scores for the first softmax class\n",
    "scores = np.array(deeplift_contribs_func(task_idx=0,\n",
    "                                         input_data_list=[X_train],\n",
    "                                         batch_size=1,\n",
    "                                         progress_update=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = scores.reshape([scores.shape[0],scores.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GoldsteinScale', 0),\n",
       " ('numarticles', 1),\n",
       " ('NumMentions', 2),\n",
       " ('avgtone', 3),\n",
       " ('numsources', 4),\n",
       " ('wti_co', 5),\n",
       " ('unemploy', 6),\n",
       " ('m1v', 7),\n",
       " ('m2v', 8),\n",
       " ('slsi', 9),\n",
       " ('vix', 10),\n",
       " ('dff', 11),\n",
       " ('Open', 12),\n",
       " ('High', 13),\n",
       " ('Low', 14),\n",
       " ('Close', 15),\n",
       " ('Adj Close', 16),\n",
       " ('Volume', 17)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X_train_df.columns,range(len(X_train_df.columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['diff']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4a55a208>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABaAAAAHWCAYAAACBlC4HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSZIkTcT/B2GOgmttxvmQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a4a542b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (25, 8)\n",
    "data = pd.DataFrame(s)\n",
    "data.columns = X_train_df.columns\n",
    "data.plot.box()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have positives and negatives so before we take the mean we want to take the abs before we take the mean in your code you were taking it after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Using your code\n",
    "mean_df = data.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoldsteinScale     0.264869\n",
       "NumMentions        0.269504\n",
       "numsources         0.502513\n",
       "m2v                0.540100\n",
       "avgtone            0.545747\n",
       "Volume             0.585855\n",
       "numarticles        0.616819\n",
       "m1v                0.619760\n",
       "slsi               0.643633\n",
       "vix                0.657326\n",
       "wit_co             0.693039\n",
       "unemploy           0.756657\n",
       "dff                1.061208\n",
       "Low                3.911338\n",
       "High               8.246509\n",
       "Adj Close         14.772058\n",
       "Close             17.435398\n",
       "Open              27.238781\n",
       "dtype: float32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df.T.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
