{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance -- Deeplift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and perpare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# np.random.seed(12345) # Set seed\n",
    "\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTEENN \n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import resample\n",
    "from keras.layers import Dense,BatchNormalization,Input,Convolution1D,GRU,Dropout\n",
    "#from keras.models import Model\n",
    "import keras\n",
    "#import pdb\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,recall_score,precision_score\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import deeplift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data obtained earlier using Michael's code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collapsed_shifted = pd.read_csv('collapsed_shifted.csv',index_col=0)\n",
    "event_idx = pd.read_csv('event_idx.csv',header=None,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train test split...\n"
     ]
    }
   ],
   "source": [
    "print ('Creating train test split...')\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(collapsed_shifted,event_idx,stratify=None,test_size=.20,shuffle=False)\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(X_train,Y_train,test_size=.20,stratify=None,shuffle=False)\n",
    "\n",
    "#Creating Copies of Data Frames these will be useful later for debugging\n",
    "X_train_df = X_train.copy(True)\n",
    "Y_train_df = Y_train.copy(True)\n",
    "Y_val_df = Y_val.copy(True)\n",
    "X_train  = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train before smote\n",
      "2780\n",
      "Number of Positives before smote\n",
      "1    166\n",
      "dtype: int64\n",
      "Performing Oversampling/Undersampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train after smote\n",
      "4584\n",
      "Number of Positive samples after smote\n",
      "2572\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#pca = PCA(whiten=True)\n",
    "#X_train = pca.fit_transform(X_train)\n",
    "#X_test = pca.transform(X_test)\n",
    "#X_val = pca.transform(X_val)\n",
    "\n",
    "print ('Length of X_train before smote')\n",
    "print (len(X_train))\n",
    "print ('Number of Positives before smote')\n",
    "print (Y_train.sum())\n",
    "\n",
    "\n",
    "print ('Performing Oversampling/Undersampling...')\n",
    "s = SMOTEENN()\n",
    "X_train,Y_train= s.fit_sample(X_train,Y_train)\n",
    "\n",
    "print ('Length of X_train after smote')\n",
    "print (len(X_train))\n",
    "\n",
    "print ('Number of Positive samples after smote')\n",
    "print (Y_train.sum())\n",
    "\n",
    "# print ('Proportion after smote {}'.format(sum(Y_train)/len(Y_train))\n",
    "\n",
    "X_train = X_train.reshape(-1,X_train.shape[1],1)\n",
    "X_test = X_test.reshape(-1,X_test.shape[1],1)\n",
    "X_val = X_val.reshape(-1,X_val.shape[1],1)\n",
    "print ('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite it to be compatiable with Deeplift.\n",
    "\n",
    "There is no MaxoutDense in the Deeplift conversion part, so I skipped them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.regularizers import l1l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import MaxoutDense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling1D\n",
    "\n",
    "def simple_keras_model(original):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(512, 5, border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5),input_shape =(original.shape[1],1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Dropout(.55))\n",
    "    model.add(Convolution1D(512,5,border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Dropout(.55))\n",
    "    model.add(Convolution1D(256,5,border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.55))\n",
    "    model.add(Convolution1D(128,5,border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.55))\n",
    "    model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.35))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    #my_model = Model([original_input], output=output)\n",
    "    optimizer_adam = keras.optimizers.adam(0.001) \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer_adam, metrics=['accuracy'])\n",
    "\n",
    "    return(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4584/4584 [==============================] - 48s - loss: 0.6770 - acc: 0.6915    \n",
      "Epoch 2/20\n",
      "4584/4584 [==============================] - 44s - loss: 0.4884 - acc: 0.7694    \n",
      "Epoch 3/20\n",
      "4584/4584 [==============================] - 47s - loss: 0.4265 - acc: 0.8072    \n",
      "Epoch 4/20\n",
      "4584/4584 [==============================] - 47s - loss: 0.3822 - acc: 0.8325    \n",
      "Epoch 5/20\n",
      "4584/4584 [==============================] - 47s - loss: 0.3264 - acc: 0.8634    \n",
      "Epoch 6/20\n",
      "4584/4584 [==============================] - 44s - loss: 0.2799 - acc: 0.8874    \n",
      "Epoch 7/20\n",
      "4584/4584 [==============================] - 43s - loss: 0.2641 - acc: 0.8979    \n",
      "Epoch 8/20\n",
      "4584/4584 [==============================] - 43s - loss: 0.2263 - acc: 0.9119    \n",
      "Epoch 9/20\n",
      "4584/4584 [==============================] - 43s - loss: 0.1950 - acc: 0.9282    \n",
      "Epoch 10/20\n",
      "4584/4584 [==============================] - 44s - loss: 0.1827 - acc: 0.9295    \n",
      "Epoch 11/20\n",
      "4584/4584 [==============================] - 48s - loss: 0.1659 - acc: 0.9376    \n",
      "Epoch 12/20\n",
      "4584/4584 [==============================] - 49s - loss: 0.1564 - acc: 0.9426    \n",
      "Epoch 13/20\n",
      "4584/4584 [==============================] - 43s - loss: 0.1498 - acc: 0.9420    \n",
      "Epoch 14/20\n",
      "4584/4584 [==============================] - 44s - loss: 0.1469 - acc: 0.9444    \n",
      "Epoch 15/20\n",
      "4584/4584 [==============================] - 43s - loss: 0.1377 - acc: 0.9535    \n",
      "Epoch 16/20\n",
      "4584/4584 [==============================] - 44s - loss: 0.1300 - acc: 0.9522    \n",
      "Epoch 17/20\n",
      "4584/4584 [==============================] - 43s - loss: 0.1274 - acc: 0.9490    \n",
      "Epoch 18/20\n",
      "4584/4584 [==============================] - 43s - loss: 0.1086 - acc: 0.9627    \n",
      "Epoch 19/20\n",
      "4584/4584 [==============================] - 44s - loss: 0.1023 - acc: 0.9651    \n",
      "Epoch 20/20\n",
      "4584/4584 [==============================] - 50s - loss: 0.1079 - acc: 0.9627    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a20a8eac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "my_model = simple_keras_model(X_train)\n",
    "my_model.fit(X_train,Y_train,nb_epoch=20,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution1d_1 (Convolution1D)  (None, 18, 512)       3072        convolution1d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 18, 512)       2048        convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 9, 512)        0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 9, 512)        0           maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 9, 512)        1311232     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 9, 512)        2048        convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 4, 512)        0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4, 512)        0           maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 4, 256)        655616      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 4, 256)        1024        convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4, 256)        0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 4, 128)        163968      dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 4, 128)        512         convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4, 128)        0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 4, 128)        49280       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 4, 128)        512         convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 4, 128)        0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_6 (Convolution1D)  (None, 4, 128)        49280       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 4, 128)        512         convolution1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 4, 128)        0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_7 (Convolution1D)  (None, 4, 128)        49280       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 4, 128)        512         convolution1d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 4, 128)        0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_8 (Convolution1D)  (None, 4, 128)        49280       dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 4, 128)        512         convolution1d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 4, 128)        0           batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 512)           0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             513         flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 2,339,201\n",
      "Trainable params: 2,335,361\n",
      "Non-trainable params: 3,840\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeplift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted from the code provided by the authors of the paper [https://arxiv.org/abs/1704.02685]:\n",
    "https://github.com/kundajelab/deeplift/blob/tensorflow/deeplift/conversion/keras_conversion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No reference provided - using zeros\n",
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n"
     ]
    }
   ],
   "source": [
    "#Convert a keras sequential model\n",
    "import deeplift\n",
    "from deeplift.conversion import keras_conversion as kc\n",
    "#MxtsMode defines the method for computing importance scores. Other supported values are:\n",
    "#Gradient, DeconvNet, GuidedBackprop and GuidedBackpropDeepLIFT (a hybrid of GuidedBackprop and DeepLIFT where\n",
    "#negative multipliers are ignored during backpropagation)\n",
    "deeplift_model = kc.convert_sequential_model(\n",
    "                    my_model,\n",
    "                    nonlinear_mxts_mode=deeplift.blobs.NonlinearMxtsMode.DeepLIFT)\n",
    "\n",
    "#Specify the index of the layer to compute the importance scores of.\n",
    "#In the example below, we find scores for the input layer, which is idx 0 in deeplift_model.get_layers()\n",
    "find_scores_layer_idx = 0\n",
    "\n",
    "#Compile the function that computes the importance scores\n",
    "#For sigmoid or softmax outputs, target_layer_idx should be -2 (the default)\n",
    "#(See \"a note on final activation layers\" in https://arxiv.org/pdf/1605.01713v2.pdf for justification)\n",
    "#For regression tasks with a linear output, target_layer_idx should be -1\n",
    "#(which simply refers to the last layer)\n",
    "#FYI: In the case of MxtsMode.DeepLIFT, the importance scores are also called \"contribution scores\"\n",
    "#If you want the multipliers instead of the contribution scores, you can use get_target_multipliers_func\n",
    "deeplift_contribs_func = deeplift_model.get_target_contribs_func(\n",
    "                            find_scores_layer_idx=find_scores_layer_idx,\n",
    "                            target_layer_idx=-2)\n",
    "\n",
    "#compute scores on inputs\n",
    "#input_data_list is a list containing the data for different input layers\n",
    "#eg: for MNIST, there is one input layer with with dimensions 1 x 28 x 28\n",
    "#In the example below, let X be an array with dimension n x 1 x 28 x 28 where n is the number of examples\n",
    "#task_idx represents the index of the node in the output layer that we wish to compute scores.\n",
    "#Eg: if the output is a 10-way softmax, and task_idx is 0, we will compute scores for the first softmax class\n",
    "scores = np.array(deeplift_contribs_func(task_idx=0,\n",
    "                                         input_data_list=[X_train],\n",
    "                                         batch_size=10,\n",
    "                                         progress_update=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = scores.reshape([scores.shape[0],scores.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GoldsteinScale', 'NumMentions', 'avgtone', 'numarticles', 'numsources',\n",
       "       'wit_co', 'unemploy', 'm1v', 'm2v', 'slsi', 'vix', 'dff', 'Open',\n",
       "       'High', 'Low', 'Close', 'Adj Close', 'Volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2EVESkaJXUSkZJTYRURKRoldRKRk/h81VOxNL1ekggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a21379fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "data=[s[i] for i in range(18)]\n",
    "plt.boxplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_mean = s.mean(axis=0)\n",
    "mean_df = pd.DataFrame(score_mean).T\n",
    "mean_df.columns = X_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>-0.955749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>-0.827570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>-0.769877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>-0.611026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>-0.576863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>-0.528706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>-0.507259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>-0.490341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>-0.237641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>-0.120099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>-0.043340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>0.054194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>0.073034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>0.114447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.164820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>0.342061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj Close</th>\n",
       "      <td>0.448655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>0.490104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "m1v            -0.955749\n",
       "wit_co         -0.827570\n",
       "unemploy       -0.769877\n",
       "avgtone        -0.611026\n",
       "GoldsteinScale -0.576863\n",
       "dff            -0.528706\n",
       "NumMentions    -0.507259\n",
       "m2v            -0.490341\n",
       "numsources     -0.237641\n",
       "numarticles    -0.120099\n",
       "Low            -0.043340\n",
       "Open            0.054194\n",
       "Close           0.073034\n",
       "vix             0.114447\n",
       "Volume          0.164820\n",
       "High            0.342061\n",
       "Adj Close       0.448655\n",
       "slsi            0.490104"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df.T.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>0.043340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>0.054194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>0.073034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>0.114447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>0.120099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.164820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>0.237641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>0.342061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj Close</th>\n",
       "      <td>0.448655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>0.490104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>0.490341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>0.507259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>0.528706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>0.576863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>0.611026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>0.769877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>0.827570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>0.955749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "Low             0.043340\n",
       "Open            0.054194\n",
       "Close           0.073034\n",
       "vix             0.114447\n",
       "numarticles     0.120099\n",
       "Volume          0.164820\n",
       "numsources      0.237641\n",
       "High            0.342061\n",
       "Adj Close       0.448655\n",
       "slsi            0.490104\n",
       "m2v             0.490341\n",
       "NumMentions     0.507259\n",
       "dff             0.528706\n",
       "GoldsteinScale  0.576863\n",
       "avgtone         0.611026\n",
       "unemploy        0.769877\n",
       "wit_co          0.827570\n",
       "m1v             0.955749"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df.abs().T.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that sentiment features like 'GoldsteinScale' and 'avgtone' are more important than volume features. But finanical features like 'unemploy' and 'wit_co' are even more important than these sentiment metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
