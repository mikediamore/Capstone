{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "## 1.) Implement Integrated Gradients\n",
    "    a.) Using two versions of Integrated Gradients. The first is a custom implementation adapted from the Authors code provided on their github\n",
    "    b.) The second is a implementation developed by Naozumi Hiranuma (hiranumn@uw.edu) \n",
    "## 2.) Update model to Keras 2.0\n",
    "    a.) Successfully transferred model to newest keras version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Michael Di Amore\n",
    "\"\"\"\n",
    "\n",
    "#Had to use python 2 for TF 1.4.0 was having problems with my virutal env\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import Query as query\n",
    "import quandl \n",
    "import numpy as np\n",
    "# np.random.seed(12345) # Set seed\n",
    "\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTEENN \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import pdb\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,recall_score,precision_score\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "\n",
    "import keras\n",
    "import tensorflow.contrib.keras as k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "#  Load Data. If you don't want to / can't run the query.\n",
    "# Basically this is all data from 2007-01-01 to 2017-10-06\n",
    "load_data = True\n",
    "if load_data == True:\n",
    "    print ('Loading Data...')\n",
    "    df_2001_2006 = pd.read_csv('Gdelt_events_20000101_20061231.csv')\n",
    "    df_2001_2006 = df_2001_2006.set_index('sqldate',drop=True).sort_index()\n",
    "    df_2007_2013 = pd.read_csv('Gdelt_events_20070101_20131231.csv')\n",
    "    df_2007_2013 = df_2007_2013.set_index('sqldate',drop=True).sort_index()\n",
    "    df_2014_01 = pd.read_csv('Gdelt_events_20140101_20140531.csv')\n",
    "    df_2014_01  = df_2014_01 .set_index('sqldate',drop=True).sort_index()\n",
    "    df_2014_02 = pd.read_csv('Gdelt_events_20140601_20141231.csv')\n",
    "    df_2014_02  = df_2014_02 .set_index('sqldate',drop=True).sort_index()\n",
    "    \n",
    "    df_2015 = pd.read_csv('Gdelt_events_20150101_20151231.csv')\n",
    "    df_2015 = df_2015.set_index('sqldate',drop=True).sort_index()\n",
    "    df_2016_2017 = pd.read_csv('Gdelt_events_20160101_20171006.csv')\n",
    "    df_2016_2017 = df_2016_2017.set_index('sqldate',drop=True).sort_index()\n",
    "    gdelt_df = pd.concat([df_2001_2006,df_2007_2013,df_2014_01,df_2014_02,df_2015,df_2016_2017])\n",
    "    \n",
    "    del df_2001_2006,df_2007_2013,df_2014_01,df_2014_02,df_2015,df_2016_2017\n",
    "    \n",
    "####\n",
    "# Set Params\n",
    "lookback_window = int(np.round(252/2))\n",
    "number_stdev = 3.5\n",
    "daily_security_vol_target = .15/np.sqrt(252) #.15 is the 10 year SPY volalility found here\n",
    "#http://performance.morningstar.com/funds/etf/ratings-risk.action?t=SPY&region=usa&culture=en-US\n",
    "####\n",
    "\n",
    "proj_id = 'capstone-v0'\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2017-10-06'\n",
    "ticker = '^GSPC'\n",
    "my_query = query.query_tool(proj_id,start_date,end_date,ticker)\n",
    "sql_query = \"\"\"\n",
    "            SELECT Actor1Name, GoldsteinScale,NumMentions,sourceurl,\n",
    "            sqldate, avgtone, numarticles, numsources,  \n",
    "            FROM [gdelt-bq:full.events] \n",
    "            WHERE sqldate > 20010101 and sqldate <= 20061231  and \n",
    "            Actor1Code like '%BUS%'and\n",
    "            Actor1Geo_CountryCode like \"%US%\"\n",
    "            \"\"\"\n",
    "if load_data == False:\n",
    "    print ('Querying Gdelt...')\n",
    "    my_query.query_gdelt(sql_query)\n",
    "    my_query.gdelt_df = my_query.gdelt_df.set_index('sqldate',drop=True).sort_index()\n",
    "    df = my_query.gdelt_df.copy(True)\n",
    "\n",
    "#Creating Labels. i.e. if change in spx_return is x standard deviations\n",
    "security_prices = my_query.query_yahoo()\n",
    "security_return = np.log(security_prices['Adj Close']).diff() #log Return\n",
    "security_vol = security_return.rolling(window=lookback_window).std().dropna()\n",
    "security_mean = security_return.rolling(window=lookback_window).mean().dropna()\n",
    "security_vol.name = 'Volatility'\n",
    "security_return = security_return.loc[security_vol.index] #First entry is NAN because of return\n",
    "# day_over_day_diff = np.abs(security_return.diff())#can subtract because of log returns\n",
    "# event_idx = [(np.abs(security_mean)+(security_vol * 3.5)) < np.abs(security_return)]\n",
    "event_idx = [((security_mean + security_vol * number_stdev) < security_return) | ((security_mean - security_vol *number_stdev) > security_return) ]\n",
    "event_idx = np.array(event_idx).astype(int).flatten()\n",
    "event_idx = pd.Series(event_idx,index=security_return.index)\n",
    "print ('Data Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quandl Loaded\n"
     ]
    }
   ],
   "source": [
    "api_key =  ''\n",
    "wti_co = my_query.query_quandl(\"FRED/DCOILWTICO\",api_key)\n",
    "unemploy = my_query.query_quandl(\"FRED/UNEMPLOY\",api_key)\n",
    "m1v = my_query.query_quandl(\"FRED/M1V\",api_key)\n",
    "m2v = my_query.query_quandl(\"FRED/M2V\",api_key)\n",
    "stressindex = my_query.query_quandl(\"FRED/STLFSI\", api_key)\n",
    "dff = my_query.query_quandl(\"FRED/DFF\",api_key)\n",
    "my_query.set_ticker('^VIX')\n",
    "vix = my_query.query_yahoo()\n",
    "vix = vix['Adj Close']\n",
    "vix.name = 'VIX'\n",
    "print ('Quandl Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quandl_others = pd.concat([wti_co,unemploy,m1v,m2v,stressindex,vix,dff],axis=1)\n",
    "quandl_others.columns = ['wit_co','unemploy','m1v','m2v','slsi','vix','dff']\n",
    "quandl_others.ffill(inplace=True)\n",
    "quandl_others.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_ts(series,lookback=lookback_window):\n",
    "    rolling_mean = series.rolling(window=lookback).mean()\n",
    "    rolling_std = series.rolling(window=lookback).std() + .10**3\n",
    "    normalized = (series-rolling_mean)/rolling_std\n",
    "    normalized = normalized.dropna()\n",
    "    return(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling using custom scaler\n"
     ]
    }
   ],
   "source": [
    "#Collapse numerical data into x,y pairs by taking means\n",
    "collapsed = gdelt_df.groupby(by=gdelt_df.index).mean()\n",
    "\n",
    "#Shift data so as only to use yesterday's news for tomorrow's prediction\n",
    "#i.e. we shift forward, using yesterday data as today\n",
    "collapsed_shifted = collapsed.shift(1)\n",
    "quandl_shifted = quandl_others.shift(1)\n",
    "spy_shifted = pd.DataFrame(security_prices).shift(1)\n",
    "\n",
    "#Scale the data in such a way that we aren't looking forward into the feature\n",
    "print ('Scaling using custom scaler')\n",
    "collapsed_shifted = collapsed_shifted.apply(normalize_ts)\n",
    "quandl_shifted = quandl_shifted.apply(normalize_ts)\n",
    "spy_shifted = spy_shifted.apply(normalize_ts)\n",
    "\n",
    "collapsed_shifted.index = pd.to_datetime(collapsed_shifted.index,format='%Y%m%d')\n",
    "collapsed_shifted = collapsed_shifted.loc[security_vol.index].dropna()\n",
    "collapsed_shifted = pd.concat([collapsed_shifted,quandl_shifted,spy_shifted],axis=1)\n",
    "event_idx = event_idx.dropna()\n",
    "collapsed_shifted = collapsed_shifted.loc[event_idx.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train test split...\n"
     ]
    }
   ],
   "source": [
    "print ('Creating train test split...')\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(collapsed_shifted,event_idx,stratify=None,test_size=.20,shuffle=False)\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(X_train,Y_train,test_size=.20,stratify=None,shuffle=False)\n",
    "\n",
    "#Creating Copies of Data Frames these will be useful later for debugging\n",
    "X_train_df = X_train.copy(True)\n",
    "Y_train_df = Y_train.copy(True)\n",
    "Y_val_df = Y_val.copy(True)\n",
    "X_train  = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train before smote\n",
      "2780\n",
      "Number of Positives before smote\n",
      "11\n",
      "Performing Oversampling/Undersampling...\n",
      "Length of X_train after smote\n",
      "5484\n",
      "Number of Positive samples after smote\n",
      "2769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pca = PCA(whiten=True)\n",
    "# X_train = pca.fit_transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n",
    "# X_val = pca.transform(X_val)\n",
    "\n",
    "print ('Length of X_train before smote')\n",
    "print (len(X_train))\n",
    "print ('Number of Positives before smote')\n",
    "print (Y_train.sum())\n",
    "\n",
    "\n",
    "print ('Performing Oversampling/Undersampling...')\n",
    "s = SMOTEENN()\n",
    "X_train,Y_train= s.fit_sample(X_train,Y_train)\n",
    "\n",
    "print ('Length of X_train after smote')\n",
    "print (len(X_train))\n",
    "\n",
    "print ('Number of Positive samples after smote')\n",
    "print (Y_train.sum())\n",
    "\n",
    "# print ('Proportion after smote {}'.format(sum(Y_train)/len(Y_train))\n",
    "\n",
    "\n",
    "# X_train = X_train.reshape(-1,X_train.shape[1],1)\n",
    "# X_test = X_test.reshape(-1,X_test.shape[1],1)\n",
    "# X_val = X_val.reshape(-1,X_val.shape[1],1)\n",
    "# print ('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,X_train.shape[1],1)\n",
    "X_test = X_test.reshape(-1,X_test.shape[1],1)\n",
    "X_val = X_val.reshape(-1,X_val.shape[1],1)\n",
    "D = X_train.shape[1]\n",
    "Y_val = np.array(Y_val)\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.int32)\n",
    "Y_val = Y_val.astype(np.int32)\n",
    "features = {'x':X_train}\n",
    "drop_rate = .55\n",
    "\n",
    "\n",
    "Y_train = Y_train.reshape(-1,1).flatten()\n",
    "Y_val = Y_val.reshape(-1,1).flatten()\n",
    "Y_test = np.array(Y_test).reshape(-1,1).flatten()\n",
    "nh1 = 512.0\n",
    "nh2 = 256.0\n",
    "nh3 = 128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def tf_model(features,labels,mode): \n",
    "tf.reset_default_graph()\n",
    "data = tf.placeholder(dtype=tf.float32,shape=[None,D,1])\n",
    "labels = tf.placeholder(dtype=tf.float32,shape=[None,1])\n",
    "is_training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model - 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D,Dropout,BatchNormalization,Input,Flatten,MaxoutDense,Dense\n",
    "from keras.constraints import maxnorm\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.legacy.layers import MaxoutDense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def simple_keras_model(original):\n",
    "    sess = tf.Session(graph=tf.get_default_graph())\n",
    "    K.set_session(sess)\n",
    "    \n",
    "    original_input = Input(shape=(original.shape[1],1),name='orig')\n",
    "    layer1 =  Conv1D(512, 5, padding='same',activation='relu',kernel_initializer='he_normal',kernel_constraint=maxnorm(0.5))(original_input)\n",
    "    layer1 = BatchNormalization()(layer1)\n",
    "    layer1 = Dropout(.55)(layer1)\n",
    "    \n",
    "    layer2 = Conv1D(512,5,padding='same',activation='relu',kernel_initializer='he_normal',kernel_constraint=maxnorm(0.5))(layer1)\n",
    "    layer2 = BatchNormalization()(layer2)\n",
    "    layer2 = Dropout(.55)(layer2)\n",
    "    \n",
    "    layer3 = Conv1D(256,5,padding='same',activation='relu',kernel_initializer='he_normal',kernel_constraint=maxnorm(0.5))(layer2)\n",
    "    layer3 = BatchNormalization()(layer3)\n",
    "    layer3 = Dropout(.55)(layer3)\n",
    "\n",
    "    layer4 = Conv1D(128,5,padding='same',activation='relu',kernel_initializer='he_normal',kernel_constraint=maxnorm(0.5))(layer3)\n",
    "    layer4 = BatchNormalization()(layer4)\n",
    "    layer4 = Dropout(.55)(layer4)\n",
    "    \n",
    "    \n",
    "    layer5 = Conv1D(128,3,padding='same',activation='relu',kernel_initializer='he_normal')(layer4)\n",
    "    layer5 = BatchNormalization()(layer5)\n",
    "    layer5 = Dropout(.35)(layer5)\n",
    "    \n",
    "\n",
    "    layer6 = Conv1D(128,3,padding='same',activation='relu',kernel_initializer='he_normal')(layer5)\n",
    "    layer6 = BatchNormalization()(layer6)\n",
    "    layer6 = Dropout(.35)(layer6)\n",
    "    \n",
    "    \n",
    "    layer7 = Conv1D(128,3,padding='same',activation='relu',kernel_initializer='he_normal')(layer6)\n",
    "    layer7 = BatchNormalization()(layer7)\n",
    "    layer7 = Dropout(.35)(layer7)\n",
    "    \n",
    "    \n",
    "    layer8 = Conv1D(128,3,padding='same',activation='relu',kernel_initializer='he_normal')(layer7)\n",
    "    layer8 = BatchNormalization()(layer8)\n",
    "    layer8 = Dropout(.35)(layer8)\n",
    "    layer8 = Flatten()(layer8)\n",
    "    \n",
    "    layer9 = MaxoutDense(1024,init='he_normal')(layer8)\n",
    "    layer9 = BatchNormalization()(layer9)\n",
    "    \n",
    "    layer10 = MaxoutDense(512,init='he_normal')(layer9)\n",
    "    layer10 = BatchNormalization()(layer10)\n",
    "    \n",
    "    layer11 = MaxoutDense(128,init='he_normal')(layer10)\n",
    "    layer11 = BatchNormalization()(layer11)\n",
    "    output = Dense(1,activation='sigmoid')(layer11)\n",
    "    \n",
    "\n",
    "    my_model = Model([original_input], output=output)\n",
    "    optimizer_adam = keras.optimizers.adam(0.001) \n",
    "    my_model.compile(loss='binary_crossentropy', optimizer=optimizer_adam, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/keras/legacy/layers.py:527: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `MaxoutDense` layer is deprecated '\n",
      "/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: UserWarning: Update your `Model` call to the Keras 2 API: `Model([<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5484/5484 [==============================] - 9s - loss: 0.3801 - acc: 0.8514     \n",
      "Epoch 2/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.1857 - acc: 0.9305     \n",
      "Epoch 3/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.1197 - acc: 0.9597     \n",
      "Epoch 4/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.1003 - acc: 0.9685     \n",
      "Epoch 5/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0898 - acc: 0.9737     \n",
      "Epoch 6/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0680 - acc: 0.9768     \n",
      "Epoch 7/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0578 - acc: 0.9810     \n",
      "Epoch 8/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0609 - acc: 0.9825     \n",
      "Epoch 9/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0406 - acc: 0.9889     \n",
      "Epoch 10/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0484 - acc: 0.9850     \n",
      "Epoch 11/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0355 - acc: 0.9896     \n",
      "Epoch 12/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0300 - acc: 0.9914     \n",
      "Epoch 13/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0328 - acc: 0.9892     \n",
      "Epoch 14/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0260 - acc: 0.9927     \n",
      "Epoch 15/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0246 - acc: 0.9942     \n",
      "Epoch 16/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0221 - acc: 0.9947     \n",
      "Epoch 17/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0206 - acc: 0.9943     \n",
      "Epoch 18/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0188 - acc: 0.9936     \n",
      "Epoch 19/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0144 - acc: 0.9960     \n",
      "Epoch 20/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0149 - acc: 0.9962     \n",
      "Epoch 21/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0177 - acc: 0.9945     \n",
      "Epoch 22/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0106 - acc: 0.9969     \n",
      "Epoch 23/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0114 - acc: 0.9962     \n",
      "Epoch 24/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0103 - acc: 0.9964     \n",
      "Epoch 25/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0119 - acc: 0.9960     \n",
      "Epoch 26/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0119 - acc: 0.9965     \n",
      "Epoch 27/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0098 - acc: 0.9964     \n",
      "Epoch 28/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0102 - acc: 0.9965     \n",
      "Epoch 29/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0105 - acc: 0.9971     \n",
      "Epoch 30/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0084 - acc: 0.9967     \n",
      "Epoch 31/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0106 - acc: 0.9964     \n",
      "Epoch 32/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0093 - acc: 0.9978     \n",
      "Epoch 33/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0088 - acc: 0.9967     \n",
      "Epoch 34/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0103 - acc: 0.9971     \n",
      "Epoch 35/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0084 - acc: 0.9971     \n",
      "Epoch 36/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0071 - acc: 0.9974     \n",
      "Epoch 37/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0040 - acc: 0.9985     \n",
      "Epoch 38/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0040 - acc: 0.9984     \n",
      "Epoch 39/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0059 - acc: 0.9976     \n",
      "Epoch 40/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0051 - acc: 0.9985     \n",
      "Epoch 41/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0036 - acc: 0.9985     \n",
      "Epoch 42/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0050 - acc: 0.9993     \n",
      "Epoch 43/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0055 - acc: 0.9980     \n",
      "Epoch 44/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0044 - acc: 0.9987     \n",
      "Epoch 45/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0066 - acc: 0.9976     \n",
      "Epoch 46/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0032 - acc: 0.9987     \n",
      "Epoch 47/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0046 - acc: 0.9980     \n",
      "Epoch 48/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0021 - acc: 0.9995     \n",
      "Epoch 49/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0022 - acc: 0.9991     \n",
      "Epoch 50/50\n",
      "5484/5484 [==============================] - 3s - loss: 0.0031 - acc: 0.9987     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce4bb929e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = simple_keras_model(X_train)\n",
    "my_model.fit(X_train,Y_train,epochs=50,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def proba_to_label(pred,threshold):\n",
    "    ones = np.array([pred > threshold])\n",
    "    \n",
    "    ones = ones.flatten()\n",
    "    return (ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probas = my_model.predict(X_val)\n",
    "predicted_classes = proba_to_label(probas,.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Standard Deviations: 3.5\n",
      " Accuracy: 0.9323741007194245\n",
      " F1: 0.0784313725490196\n",
      " RoC: 0.80009633911368\n",
      " Precision: 0.041666666666666664\n",
      " Recall: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(Y_val,predicted_classes)\n",
    "f1 = f1_score(Y_val,predicted_classes)\n",
    "roc = roc_auc_score(Y_val,predicted_classes)\n",
    "prec = precision_score(Y_val,predicted_classes)\n",
    "recall= recall_score(Y_val,predicted_classes)\n",
    "\n",
    "\n",
    "print (' Standard Deviations: {}'.format(number_stdev))\n",
    "print (' Accuracy: {}'.format(acc))\n",
    "print (' F1: {}'.format(f1))\n",
    "print (' RoC: {}'.format(roc))\n",
    "print (' Precision: {}'.format(prec))\n",
    "print (' Recall: {}'.format(recall))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation adapted from example codegenerously given by the authors of the paper on their github\n",
    "#Adjusted from https://github.com/ankurtaly/Integrated-Gradients/blob/master/attributions.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def T(layer,graph):\n",
    "    #Helper for getting layer output tensor\n",
    "    return graph.get_tensor_by_name(layer)\n",
    "\n",
    "def scorer(sess,tensor,data):\n",
    "      return sess.run(tensor, {'orig:0':data,is_training:False,K.learning_phase():0})\n",
    "    \n",
    "def top_label_and_score(data,graph):\n",
    "    '''\n",
    "    Returns the label and score of the object class\n",
    "    that receives the highest SOFTMAX score.\n",
    "    '''\n",
    "    # Evaluate the SOFTMAX output layer for the image and\n",
    "    # determine the label for the highest-scoring class\n",
    "    t_softmax = tf.reduce_mean(T('dense_1/Sigmoid:0',graph), reduction_indices=0)\n",
    "#     t_softmax = T('dense_3/Sigmoid:0',graph)\n",
    "    scores = scorer(sess, t_softmax, data)\n",
    "    id = np.argmax(scores)\n",
    "    return labels[id], scores[id]\n",
    "\n",
    "def output_label_tensor(label,graph):\n",
    "    '''Returns a tensor (shape: scalar) representing the SOFTMAX\n",
    "     for a given label.\n",
    "    '''\n",
    "    lab_index = np.where(np.in1d(Y_train, label))[0][0]\n",
    "    lab_index = lab_index.astype(np.int32)\n",
    "#     t_softmax = T('dense_3/Sigmoid:0',graph)\n",
    "    t_softmax = tf.reduce_sum(T('dense_1/Sigmoid:0',graph), reduction_indices=0)\n",
    "\n",
    "    return t_softmax[lab_index]\n",
    "\n",
    "def integrated_gradients(data, label,graph, steps=10**6):\n",
    "    '''\n",
    "     Returns attributions for the prediction label based\n",
    "     on integrated gradients at the image.\n",
    "\n",
    "     Specifically, the method returns the dot product of the image\n",
    "     and the average of the gradients of the prediction label (w.r.t.\n",
    "     the image) at uniformly spaced scalings of the provided data.\n",
    "\n",
    "    '''\n",
    "    t_output = output_label_tensor(label,graph)  # shape: scalar\n",
    "    t_grad = tf.gradients(t_output, T('orig:0',graph))[0]\n",
    "    grads = scorer(sess, t_grad, data)\n",
    "    return data*np.average(grads, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on X_train and get predictions from probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proba_for_ig = my_model.predict(X_train)\n",
    "pred_for_ig = proba_to_label(proba_for_ig,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get session and graph for Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "ig = integrated_gradients(X_train,pred_for_ig,sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_ig = ig.sum(axis=0)\n",
    "ig_df = pd.DataFrame(total_ig).T\n",
    "ig_df.columns = X_train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Integrated Gradients reveal that the GDELT features are not contributing much at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>-6.264696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj Close</th>\n",
       "      <td>-2.337755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>-1.517412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>-0.712660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>-0.197660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>-0.005180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>-0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>0.176337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>0.304550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>0.959324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>1.117761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>1.331781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>1.982337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>7.070244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>7.249289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>7.988078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>9.223415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>17.175245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "High            -6.264696\n",
       "Adj Close       -2.337755\n",
       "Volume          -1.517412\n",
       "avgtone         -0.712660\n",
       "GoldsteinScale  -0.197660\n",
       "numarticles     -0.005180\n",
       "NumMentions     -0.000495\n",
       "m2v              0.176337\n",
       "unemploy         0.304550\n",
       "numsources       0.959324\n",
       "m1v              1.117761\n",
       "wit_co           1.331781\n",
       "dff              1.982337\n",
       "Close            7.070244\n",
       "Low              7.249289\n",
       "Open             7.988078\n",
       "vix              9.223415\n",
       "slsi            17.175245"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_df.T.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>0.005180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>0.176337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>0.197660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>0.304550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>0.712660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>0.959324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>1.117761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>1.331781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>1.517412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>1.982337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj Close</th>\n",
       "      <td>2.337755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>6.264696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>7.070244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>7.249289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>7.988078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>9.223415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>17.175245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "NumMentions      0.000495\n",
       "numarticles      0.005180\n",
       "m2v              0.176337\n",
       "GoldsteinScale   0.197660\n",
       "unemploy         0.304550\n",
       "avgtone          0.712660\n",
       "numsources       0.959324\n",
       "m1v              1.117761\n",
       "wit_co           1.331781\n",
       "Volume           1.517412\n",
       "dff              1.982337\n",
       "Adj Close        2.337755\n",
       "High             6.264696\n",
       "Close            7.070244\n",
       "Low              7.249289\n",
       "Open             7.988078\n",
       "vix              9.223415\n",
       "slsi            17.175245"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_df.abs().T.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients 2\n",
    "#### https://github.com/hiranumn/IntegratedGradients/blob/master/IntegratedGradients.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import IntegratedGradients as ig2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "int_grad = ig2.integrated_gradients(model=my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "cumulative_sum = np.zeros(X_train.shape[1])\n",
    "for i in range(len(X_train)):\n",
    "    cumulative_sum+= int_grad.explain(X_train[i],num_steps=100).flatten()\n",
    "    if i % 1000 == 0:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(cumulative_sum).T\n",
    "feature_imp.columns = X_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>-14.780217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>-12.177998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>-4.530241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>-4.483030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>-2.631569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>-2.263398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>-2.260619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>-0.162094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>4.890420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>6.836723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj Close</th>\n",
       "      <td>7.371895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>8.865716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>9.300324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>11.414517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>29.638005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>29.839416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>36.278204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>42.861096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "High           -14.780217\n",
       "unemploy       -12.177998\n",
       "avgtone         -4.530241\n",
       "NumMentions     -4.483030\n",
       "numsources      -2.631569\n",
       "m1v             -2.263398\n",
       "GoldsteinScale  -2.260619\n",
       "numarticles     -0.162094\n",
       "wit_co           4.890420\n",
       "Low              6.836723\n",
       "Adj Close        7.371895\n",
       "m2v              8.865716\n",
       "Volume           9.300324\n",
       "dff             11.414517\n",
       "Close           29.638005\n",
       "vix             29.839416\n",
       "Open            36.278204\n",
       "slsi            42.861096"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.T.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>0.162094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>2.260619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>2.263398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>2.631569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>4.483030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>4.530241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>4.890420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>6.836723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj Close</th>\n",
       "      <td>7.371895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>8.865716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>9.300324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>11.414517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>12.177998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>14.780217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>29.638005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>29.839416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>36.278204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>42.861096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "numarticles      0.162094\n",
       "GoldsteinScale   2.260619\n",
       "m1v              2.263398\n",
       "numsources       2.631569\n",
       "NumMentions      4.483030\n",
       "avgtone          4.530241\n",
       "wit_co           4.890420\n",
       "Low              6.836723\n",
       "Adj Close        7.371895\n",
       "m2v              8.865716\n",
       "Volume           9.300324\n",
       "dff             11.414517\n",
       "unemploy        12.177998\n",
       "High            14.780217\n",
       "Close           29.638005\n",
       "vix             29.839416\n",
       "Open            36.278204\n",
       "slsi            42.861096"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.T.abs().sort_values(by=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results 2\n",
    "\n",
    "The other code reveals a similar story with regard to GDELT, as it's not a heavily contributing set of features. However the order of the financial features differs slightly from my implementation"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
