{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "## 1.) Implement Integrated Gradients\n",
    "    a.) Using two versions of Integrated Gradients. The first is a custom implementation adapted from the Authors code provided on their github\n",
    "    b.) The second is a implementation developed by Naozumi Hiranuma (hiranumn@uw.edu) \n",
    "## 2.) Update model to Keras 2.0\n",
    "    a.) Successfully transferred model to newest keras version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Michael Di Amore\n",
    "\"\"\"\n",
    "\n",
    "#Had to use python 2 for TF 1.4.0 was having problems with my virutal env\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import Query as query\n",
    "import quandl \n",
    "import numpy as np\n",
    "# np.random.seed(12345) # Set seed\n",
    "\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTEENN \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import pdb\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,recall_score,precision_score\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "\n",
    "import keras\n",
    "import tensorflow.contrib.keras as k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "#  Load Data. If you don't want to / can't run the query.\n",
    "# Basically this is all data from 2007-01-01 to 2017-10-06\n",
    "load_data = True\n",
    "if load_data == True:\n",
    "    print ('Loading Data...')\n",
    "    df_2001_2006 = pd.read_csv('Gdelt_events_20000101_20061231.csv')\n",
    "    df_2001_2006 = df_2001_2006.set_index('sqldate',drop=True).sort_index()\n",
    "    df_2007_2013 = pd.read_csv('Gdelt_events_20070101_20131231.csv')\n",
    "    df_2007_2013 = df_2007_2013.set_index('sqldate',drop=True).sort_index()\n",
    "    df_2014_01 = pd.read_csv('Gdelt_events_20140101_20140531.csv')\n",
    "    df_2014_01  = df_2014_01 .set_index('sqldate',drop=True).sort_index()\n",
    "    df_2014_02 = pd.read_csv('Gdelt_events_20140601_20141231.csv')\n",
    "    df_2014_02  = df_2014_02 .set_index('sqldate',drop=True).sort_index()\n",
    "    \n",
    "    df_2015 = pd.read_csv('Gdelt_events_20150101_20151231.csv')\n",
    "    df_2015 = df_2015.set_index('sqldate',drop=True).sort_index()\n",
    "    df_2016_2017 = pd.read_csv('Gdelt_events_20160101_20171006.csv')\n",
    "    df_2016_2017 = df_2016_2017.set_index('sqldate',drop=True).sort_index()\n",
    "    gdelt_df = pd.concat([df_2001_2006,df_2007_2013,df_2014_01,df_2014_02,df_2015,df_2016_2017])\n",
    "    \n",
    "    del df_2001_2006,df_2007_2013,df_2014_01,df_2014_02,df_2015,df_2016_2017\n",
    "    \n",
    "####\n",
    "# Set Params\n",
    "lookback_window = int(np.round(252/2))\n",
    "number_stdev = 3.5\n",
    "daily_security_vol_target = .15/np.sqrt(252) #.15 is the 10 year SPY volalility found here\n",
    "#http://performance.morningstar.com/funds/etf/ratings-risk.action?t=SPY&region=usa&culture=en-US\n",
    "####\n",
    "\n",
    "proj_id = 'capstone-v0'\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2017-10-06'\n",
    "ticker = '^GSPC'\n",
    "my_query = query.query_tool(proj_id,start_date,end_date,ticker)\n",
    "sql_query = \"\"\"\n",
    "            SELECT Actor1Name, GoldsteinScale,NumMentions,sourceurl,\n",
    "            sqldate, avgtone, numarticles, numsources,  \n",
    "            FROM [gdelt-bq:full.events] \n",
    "            WHERE sqldate > 20010101 and sqldate <= 20061231  and \n",
    "            Actor1Code like '%BUS%'and\n",
    "            Actor1Geo_CountryCode like \"%US%\"\n",
    "            \"\"\"\n",
    "if load_data == False:\n",
    "    print ('Querying Gdelt...')\n",
    "    my_query.query_gdelt(sql_query)\n",
    "    my_query.gdelt_df = my_query.gdelt_df.set_index('sqldate',drop=True).sort_index()\n",
    "    df = my_query.gdelt_df.copy(True)\n",
    "\n",
    "#Creating Labels. i.e. if change in spx_return is x standard deviations\n",
    "security_prices = my_query.query_yahoo()\n",
    "security_return = np.log(security_prices['Adj Close']).diff() #log Return\n",
    "security_vol = security_return.rolling(window=lookback_window).std().dropna()\n",
    "security_mean = security_return.rolling(window=lookback_window).mean().dropna()\n",
    "security_vol.name = 'Volatility'\n",
    "security_return = security_return.loc[security_vol.index] #First entry is NAN because of return\n",
    "# day_over_day_diff = np.abs(security_return.diff())#can subtract because of log returns\n",
    "# event_idx = [(np.abs(security_mean)+(security_vol * 3.5)) < np.abs(security_return)]\n",
    "event_idx = [((security_mean + security_vol * number_stdev) < security_return) | ((security_mean - security_vol *number_stdev) > security_return) ]\n",
    "event_idx = np.array(event_idx).astype(int).flatten()\n",
    "event_idx = pd.Series(event_idx,index=security_return.index)\n",
    "print ('Data Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quandl Loaded\n"
     ]
    }
   ],
   "source": [
    "api_key =  ''\n",
    "wti_co = my_query.query_quandl(\"FRED/DCOILWTICO\",api_key)\n",
    "unemploy = my_query.query_quandl(\"FRED/UNEMPLOY\",api_key)\n",
    "m1v = my_query.query_quandl(\"FRED/M1V\",api_key)\n",
    "m2v = my_query.query_quandl(\"FRED/M2V\",api_key)\n",
    "stressindex = my_query.query_quandl(\"FRED/STLFSI\", api_key)\n",
    "dff = my_query.query_quandl(\"FRED/DFF\",api_key)\n",
    "my_query.set_ticker('^VIX')\n",
    "vix = my_query.query_yahoo()\n",
    "vix = vix['Adj Close']\n",
    "vix.name = 'VIX'\n",
    "print ('Quandl Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quandl_others = pd.concat([wti_co,unemploy,m1v,m2v,stressindex,vix,dff],axis=1)\n",
    "quandl_others.columns = ['wit_co','unemploy','m1v','m2v','slsi','vix','dff']\n",
    "quandl_others.ffill(inplace=True)\n",
    "quandl_others.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_ts(series,lookback=lookback_window):\n",
    "    rolling_mean = series.rolling(window=lookback).mean()\n",
    "    rolling_std = series.rolling(window=lookback).std() + .10**3\n",
    "    normalized = (series-rolling_mean)/rolling_std\n",
    "    normalized = normalized.dropna()\n",
    "    return(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling using custom scaler\n"
     ]
    }
   ],
   "source": [
    "#Collapse numerical data into x,y pairs by taking means\n",
    "collapsed = gdelt_df.groupby(by=gdelt_df.index).mean()\n",
    "\n",
    "#Shift data so as only to use yesterday's news for tomorrow's prediction\n",
    "#i.e. we shift forward, using yesterday data as today\n",
    "collapsed_shifted = collapsed.shift(1)\n",
    "quandl_shifted = quandl_others.shift(1)\n",
    "\n",
    "#Scale the data in such a way that we aren't looking forward into the feature\n",
    "print ('Scaling using custom scaler')\n",
    "collapsed_shifted = collapsed_shifted.apply(normalize_ts)\n",
    "quandl_shifted = quandl_shifted.apply(normalize_ts)\n",
    "\n",
    "collapsed_shifted.index = pd.to_datetime(collapsed_shifted.index,format='%Y%m%d')\n",
    "collapsed_shifted = collapsed_shifted.loc[security_vol.index].dropna()\n",
    "collapsed_shifted = pd.concat([collapsed_shifted,quandl_shifted],axis=1)\n",
    "event_idx = event_idx.dropna()\n",
    "collapsed_shifted = collapsed_shifted.loc[event_idx.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train test split...\n"
     ]
    }
   ],
   "source": [
    "print ('Creating train test split...')\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(collapsed_shifted,event_idx,stratify=None,test_size=.20,shuffle=False)\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(X_train,Y_train,test_size=.20,stratify=None,shuffle=False)\n",
    "\n",
    "#Creating Copies of Data Frames these will be useful later for debugging\n",
    "X_train_df = X_train.copy(True)\n",
    "Y_train_df = Y_train.copy(True)\n",
    "Y_val_df = Y_val.copy(True)\n",
    "X_train  = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train before smote\n",
      "2780\n",
      "Number of Positives before smote\n",
      "11\n",
      "Performing Oversampling/Undersampling...\n",
      "Length of X_train after smote\n",
      "5479\n",
      "Number of Positive samples after smote\n",
      "2769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pca = PCA(whiten=True)\n",
    "# X_train = pca.fit_transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n",
    "# X_val = pca.transform(X_val)\n",
    "\n",
    "print ('Length of X_train before smote')\n",
    "print (len(X_train))\n",
    "print ('Number of Positives before smote')\n",
    "print (Y_train.sum())\n",
    "\n",
    "\n",
    "print ('Performing Oversampling/Undersampling...')\n",
    "s = SMOTEENN()\n",
    "X_train,Y_train= s.fit_sample(X_train,Y_train)\n",
    "\n",
    "print ('Length of X_train after smote')\n",
    "print (len(X_train))\n",
    "\n",
    "print ('Number of Positive samples after smote')\n",
    "print (Y_train.sum())\n",
    "\n",
    "# print ('Proportion after smote {}'.format(sum(Y_train)/len(Y_train))\n",
    "\n",
    "\n",
    "# X_train = X_train.reshape(-1,X_train.shape[1],1)\n",
    "# X_test = X_test.reshape(-1,X_test.shape[1],1)\n",
    "# X_val = X_val.reshape(-1,X_val.shape[1],1)\n",
    "# print ('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,X_train.shape[1],1)\n",
    "X_test = X_test.reshape(-1,X_test.shape[1],1)\n",
    "X_val = X_val.reshape(-1,X_val.shape[1],1)\n",
    "D = X_train.shape[1]\n",
    "Y_val = np.array(Y_val)\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.int32)\n",
    "Y_val = Y_val.astype(np.int32)\n",
    "features = {'x':X_train}\n",
    "drop_rate = .55\n",
    "\n",
    "\n",
    "Y_train = Y_train.reshape(-1,1).flatten()\n",
    "Y_val = Y_val.reshape(-1,1).flatten()\n",
    "Y_test = np.array(Y_test).reshape(-1,1).flatten()\n",
    "nh1 = 512.0\n",
    "nh2 = 256.0\n",
    "nh3 = 128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5479,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def tf_model(features,labels,mode): \n",
    "tf.reset_default_graph()\n",
    "data = tf.placeholder(dtype=tf.float32,shape=[None,D,1])\n",
    "labels = tf.placeholder(dtype=tf.float32,shape=[None,1])\n",
    "is_training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model - 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D,Dropout,BatchNormalization,Input,Flatten,MaxoutDense,Dense\n",
    "from keras.constraints import maxnorm\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.legacy.layers import MaxoutDense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def simple_keras_model(original):\n",
    "    sess = tf.Session(graph=tf.get_default_graph())\n",
    "    K.set_session(sess)\n",
    "    \n",
    "    original_input = Input(shape=(original.shape[1],1),name='orig')\n",
    "    layer1 =  Conv1D(512, 5, padding='same',activation='relu',kernel_initializer='he_normal',kernel_constraint=maxnorm(0.5))(original_input)\n",
    "    layer1 = BatchNormalization()(layer1)\n",
    "    layer1 = Dropout(.55)(layer1)\n",
    "    \n",
    "    layer2 = Conv1D(512,5,padding='same',activation='relu',kernel_initializer='he_normal',kernel_constraint=maxnorm(0.5))(layer1)\n",
    "    layer2 = BatchNormalization()(layer2)\n",
    "    layer2 = Dropout(.55)(layer2)\n",
    "    \n",
    "    layer3 = Conv1D(256,5,padding='same',activation='relu',kernel_initializer='he_normal',kernel_constraint=maxnorm(0.5))(layer2)\n",
    "    layer3 = BatchNormalization()(layer3)\n",
    "    layer3 = Dropout(.55)(layer3)\n",
    "\n",
    "    layer4 = Conv1D(128,5,padding='same',activation='relu',kernel_initializer='he_normal',kernel_constraint=maxnorm(0.5))(layer3)\n",
    "    layer4 = BatchNormalization()(layer4)\n",
    "    layer4 = Dropout(.55)(layer4)\n",
    "    \n",
    "    \n",
    "    layer5 = Conv1D(128,3,padding='same',activation='relu',kernel_initializer='he_normal')(layer4)\n",
    "    layer5 = BatchNormalization()(layer5)\n",
    "    layer5 = Dropout(.35)(layer5)\n",
    "    \n",
    "\n",
    "    layer6 = Conv1D(128,3,padding='same',activation='relu',kernel_initializer='he_normal')(layer5)\n",
    "    layer6 = BatchNormalization()(layer6)\n",
    "    layer6 = Dropout(.35)(layer6)\n",
    "    \n",
    "    \n",
    "    layer7 = Conv1D(128,3,padding='same',activation='relu',kernel_initializer='he_normal')(layer6)\n",
    "    layer7 = BatchNormalization()(layer7)\n",
    "    layer7 = Dropout(.35)(layer7)\n",
    "    \n",
    "    \n",
    "    layer8 = Conv1D(128,3,padding='same',activation='relu',kernel_initializer='he_normal')(layer7)\n",
    "    layer8 = BatchNormalization()(layer8)\n",
    "    layer8 = Dropout(.35)(layer8)\n",
    "    layer8 = Flatten()(layer8)\n",
    "    \n",
    "    layer9 = MaxoutDense(1024,init='he_normal')(layer8)\n",
    "    layer9 = BatchNormalization()(layer9)\n",
    "    \n",
    "    layer10 =MaxoutDense(512,init='he_normal')(layer9)\n",
    "    layer10 = BatchNormalization()(layer10)\n",
    "    \n",
    "    layer11 = MaxoutDense(128,init='he_normal')(layer10)\n",
    "    layer11 = BatchNormalization()(layer11)\n",
    "    output = Dense(1,activation='sigmoid')(layer11)\n",
    "    \n",
    "\n",
    "    my_model = Model([original_input], output=output)\n",
    "    optimizer_adam = keras.optimizers.adam(0.001) \n",
    "    my_model.compile(loss='binary_crossentropy', optimizer=optimizer_adam, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/keras/legacy/layers.py:527: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `MaxoutDense` layer is deprecated '\n",
      "/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: UserWarning: Update your `Model` call to the Keras 2 API: `Model([<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "5479/5479 [==============================] - 7s - loss: 0.3787 - acc: 0.8500     \n",
      "Epoch 2/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.1513 - acc: 0.9496     \n",
      "Epoch 3/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.1013 - acc: 0.9655     \n",
      "Epoch 4/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0804 - acc: 0.9735     \n",
      "Epoch 5/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0764 - acc: 0.9752     \n",
      "Epoch 6/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0627 - acc: 0.9810     \n",
      "Epoch 7/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0479 - acc: 0.9836     \n",
      "Epoch 8/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0403 - acc: 0.9892     \n",
      "Epoch 9/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0404 - acc: 0.9881     \n",
      "Epoch 10/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0333 - acc: 0.9885     \n",
      "Epoch 11/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0309 - acc: 0.9918     \n",
      "Epoch 12/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0272 - acc: 0.9927     \n",
      "Epoch 13/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0224 - acc: 0.9934     \n",
      "Epoch 14/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0370 - acc: 0.9887     \n",
      "Epoch 15/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0250 - acc: 0.9920     \n",
      "Epoch 16/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0206 - acc: 0.9931     \n",
      "Epoch 17/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0178 - acc: 0.9953     \n",
      "Epoch 18/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0188 - acc: 0.9953     \n",
      "Epoch 19/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0145 - acc: 0.9958     \n",
      "Epoch 20/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0117 - acc: 0.9962     \n",
      "Epoch 21/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0128 - acc: 0.9963     \n",
      "Epoch 22/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0103 - acc: 0.9958     \n",
      "Epoch 23/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0143 - acc: 0.9963     \n",
      "Epoch 24/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0095 - acc: 0.9969     \n",
      "Epoch 25/25\n",
      "5479/5479 [==============================] - 2s - loss: 0.0134 - acc: 0.9956     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f307fae7048>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = simple_keras_model(X_train)\n",
    "my_model.fit(X_train,Y_train,epochs=25,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def proba_to_label(pred,threshold):\n",
    "    ones = np.array([pred > threshold])\n",
    "    \n",
    "    ones = ones.flatten()\n",
    "    return (ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probas = my_model.predict(X_val)\n",
    "predicted_classes = proba_to_label(probas,.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Standard Deviations: 3.5\n",
      " Accuracy: 0.9237410071942446\n",
      " F1: 0.10169491525423728\n",
      " RoC: 0.9617052023121387\n",
      " Precision: 0.05357142857142857\n",
      " Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(Y_val,predicted_classes)\n",
    "f1 = f1_score(Y_val,predicted_classes)\n",
    "roc = roc_auc_score(Y_val,predicted_classes)\n",
    "prec = precision_score(Y_val,predicted_classes)\n",
    "recall= recall_score(Y_val,predicted_classes)\n",
    "\n",
    "\n",
    "print (' Standard Deviations: {}'.format(number_stdev))\n",
    "print (' Accuracy: {}'.format(acc))\n",
    "print (' F1: {}'.format(f1))\n",
    "print (' RoC: {}'.format(roc))\n",
    "print (' Precision: {}'.format(prec))\n",
    "print (' Recall: {}'.format(recall))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation adapted from example codegenerously given by the authors of the paper on their github\n",
    "#Adjusted from https://github.com/ankurtaly/Integrated-Gradients/blob/master/attributions.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def T(layer,graph):\n",
    "    #Helper for getting layer output tensor\n",
    "    return graph.get_tensor_by_name(layer)\n",
    "\n",
    "def scorer(sess,tensor,data):\n",
    "      return sess.run(tensor, {'orig:0':data,is_training:False,K.learning_phase():0})\n",
    "    \n",
    "def top_label_and_score(data,graph):\n",
    "    '''\n",
    "    Returns the label and score of the object class\n",
    "    that receives the highest SOFTMAX score.\n",
    "    '''\n",
    "    # Evaluate the SOFTMAX output layer for the image and\n",
    "    # determine the label for the highest-scoring class\n",
    "    t_softmax = tf.reduce_mean(T('dense_1/Sigmoid:0',graph), reduction_indices=0)\n",
    "#     t_softmax = T('dense_3/Sigmoid:0',graph)\n",
    "    scores = scorer(sess, t_softmax, data)\n",
    "    id = np.argmax(scores)\n",
    "    return labels[id], scores[id]\n",
    "\n",
    "def output_label_tensor(label,graph):\n",
    "    '''Returns a tensor (shape: scalar) representing the SOFTMAX\n",
    "     for a given label.\n",
    "    '''\n",
    "    lab_index = np.where(np.in1d(Y_train, label))[0][0]\n",
    "    lab_index = lab_index.astype(np.int32)\n",
    "#     t_softmax = T('dense_3/Sigmoid:0',graph)\n",
    "    t_softmax = tf.reduce_sum(T('dense_1/Sigmoid:0',graph), reduction_indices=0)\n",
    "\n",
    "    return t_softmax[lab_index]\n",
    "\n",
    "def integrated_gradients(data, label,graph, steps=10**6):\n",
    "    '''\n",
    "     Returns attributions for the prediction label based\n",
    "     on integrated gradients at the image.\n",
    "\n",
    "     Specifically, the method returns the dot product of the image\n",
    "     and the average of the gradients of the prediction label (w.r.t.\n",
    "     the image) at uniformly spaced scalings of the provided data.\n",
    "\n",
    "    '''\n",
    "    t_output = output_label_tensor(label,graph)  # shape: scalar\n",
    "    t_grad = tf.gradients(t_output, T('orig:0',graph))[0]\n",
    "    grads = scorer(sess, t_grad, data)\n",
    "    return data*np.average(grads, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on X_train and get predictions from probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proba_for_ig = my_model.predict(X_train)\n",
    "pred_for_ig = proba_to_label(proba_for_ig,.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get session and graph for Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "ig = integrated_gradients(X_train,pred_for_ig,sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_ig = ig.sum(axis=0)\n",
    "ig_df = pd.DataFrame(total_ig).T\n",
    "ig_df.columns = X_train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Integrated Gradients reveal that the GDELT features are not contributing much at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>-28.249872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>-8.562857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>-4.975959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>-2.681561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>-1.719554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>-1.701710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>-1.069570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>-0.421932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>-0.025769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>-0.025184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>-0.000829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>0.546937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "vix            -28.249872\n",
       "m2v             -8.562857\n",
       "m1v             -4.975959\n",
       "slsi            -2.681561\n",
       "unemploy        -1.719554\n",
       "wit_co          -1.701710\n",
       "avgtone         -1.069570\n",
       "numsources      -0.421932\n",
       "GoldsteinScale  -0.025769\n",
       "NumMentions     -0.025184\n",
       "numarticles     -0.000829\n",
       "dff              0.546937"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_df.T.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>0.000829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>0.025184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>0.025769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>0.421932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>0.546937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>1.069570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>1.701710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>1.719554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>2.681561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>4.975959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>8.562857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>28.249872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "numarticles      0.000829\n",
       "NumMentions      0.025184\n",
       "GoldsteinScale   0.025769\n",
       "numsources       0.421932\n",
       "dff              0.546937\n",
       "avgtone          1.069570\n",
       "wit_co           1.701710\n",
       "unemploy         1.719554\n",
       "slsi             2.681561\n",
       "m1v              4.975959\n",
       "m2v              8.562857\n",
       "vix             28.249872"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_df.abs().T.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients 2\n",
    "#### https://github.com/hiranumn/IntegratedGradients/blob/master/IntegratedGradients.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import IntegratedGradients as ig2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "int_grad = ig2.integrated_gradients(model=my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "cumulative_sum = np.zeros(X_train.shape[1])\n",
    "for i in range(len(X_train)):\n",
    "    cumulative_sum+= int_grad.explain(X_train[i],num_steps=100).flatten()\n",
    "    if i % 1000 == 0:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(cumulative_sum).T\n",
    "feature_imp.columns = X_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>-67.333618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>-33.543937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>-30.010685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>-28.310898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>-21.436498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>-18.222832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>-8.722337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>-8.638571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>-8.567603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>-6.529546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>-4.568454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>-0.279314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "vix            -67.333618\n",
       "m1v            -33.543937\n",
       "slsi           -30.010685\n",
       "wit_co         -28.310898\n",
       "unemploy       -21.436498\n",
       "m2v            -18.222832\n",
       "avgtone         -8.722337\n",
       "dff             -8.638571\n",
       "numarticles     -8.567603\n",
       "NumMentions     -6.529546\n",
       "numsources      -4.568454\n",
       "GoldsteinScale  -0.279314"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.T.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>0.279314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>4.568454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>6.529546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>8.567603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>8.638571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>8.722337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>18.222832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>21.436498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>28.310898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>30.010685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>33.543937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>67.333618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "GoldsteinScale   0.279314\n",
       "numsources       4.568454\n",
       "NumMentions      6.529546\n",
       "numarticles      8.567603\n",
       "dff              8.638571\n",
       "avgtone          8.722337\n",
       "m2v             18.222832\n",
       "unemploy        21.436498\n",
       "wit_co          28.310898\n",
       "slsi            30.010685\n",
       "m1v             33.543937\n",
       "vix             67.333618"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.T.abs().sort_values(by=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results 2\n",
    "\n",
    "The other code reveals a similar story with regard to GDELT, as it's not a heavily contributing set of features. However the order of the financial features differs slightly from my implementation"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
