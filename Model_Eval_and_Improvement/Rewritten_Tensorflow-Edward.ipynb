{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "1.) Rewrite full model in tensorflow\n",
    "\n",
    "2.) Take a bayesian approach and add priors on the weights to quantify uncertainity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Michael Di Amore\n",
    "\"\"\"\n",
    "\n",
    "#Had to use python 2 for TF 1.4.0 was having problems with my virutal env\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import Query as query\n",
    "import quandl \n",
    "import numpy as np\n",
    "# np.random.seed(12345) # Set seed\n",
    "\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTEENN \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import pdb\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,recall_score,precision_score\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "\n",
    "import keras\n",
    "import tensorflow.contrib.keras as k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "#  Load Data. If you don't want to / can't run the query.\n",
    "# Basically this is all data from 2007-01-01 to 2017-10-06\n",
    "load_data = True\n",
    "if load_data == True:\n",
    "    print ('Loading Data...')\n",
    "    df_2001_2006 = pd.read_csv('Gdelt_events_20000101_20061231.csv')\n",
    "    df_2001_2006 = df_2001_2006.set_index('sqldate',drop=True).sort_index()\n",
    "    df_2007_2013 = pd.read_csv('Gdelt_events_20070101_20131231.csv')\n",
    "    df_2007_2013 = df_2007_2013.set_index('sqldate',drop=True).sort_index()\n",
    "    df_2014_01 = pd.read_csv('Gdelt_events_20140101_20140531.csv')\n",
    "    df_2014_01  = df_2014_01 .set_index('sqldate',drop=True).sort_index()\n",
    "    df_2014_02 = pd.read_csv('Gdelt_events_20140601_20141231.csv')\n",
    "    df_2014_02  = df_2014_02 .set_index('sqldate',drop=True).sort_index()\n",
    "    \n",
    "    df_2015 = pd.read_csv('Gdelt_events_20150101_20151231.csv')\n",
    "    df_2015 = df_2015.set_index('sqldate',drop=True).sort_index()\n",
    "    df_2016_2017 = pd.read_csv('Gdelt_events_20160101_20171006.csv')\n",
    "    df_2016_2017 = df_2016_2017.set_index('sqldate',drop=True).sort_index()\n",
    "    gdelt_df = pd.concat([df_2001_2006,df_2007_2013,df_2014_01,df_2014_02,df_2015,df_2016_2017])\n",
    "    \n",
    "    del df_2001_2006,df_2007_2013,df_2014_01,df_2014_02,df_2015,df_2016_2017\n",
    "    \n",
    "####\n",
    "# Set Params\n",
    "lookback_window = int(np.round(252/2))\n",
    "number_stdev = 3.5\n",
    "daily_security_vol_target = .15/np.sqrt(252) #.15 is the 10 year SPY volalility found here\n",
    "#http://performance.morningstar.com/funds/etf/ratings-risk.action?t=SPY&region=usa&culture=en-US\n",
    "####\n",
    "\n",
    "proj_id = 'capstone-v0'\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2017-10-06'\n",
    "ticker = '^GSPC'\n",
    "my_query = query.query_tool(proj_id,start_date,end_date,ticker)\n",
    "sql_query = \"\"\"\n",
    "            SELECT Actor1Name, GoldsteinScale,NumMentions,sourceurl,\n",
    "            sqldate, avgtone, numarticles, numsources,  \n",
    "            FROM [gdelt-bq:full.events] \n",
    "            WHERE sqldate > 20010101 and sqldate <= 20061231  and \n",
    "            Actor1Code like '%BUS%'and\n",
    "            Actor1Geo_CountryCode like \"%US%\"\n",
    "            \"\"\"\n",
    "if load_data == False:\n",
    "    print ('Querying Gdelt...')\n",
    "    my_query.query_gdelt(sql_query)\n",
    "    my_query.gdelt_df = my_query.gdelt_df.set_index('sqldate',drop=True).sort_index()\n",
    "    df = my_query.gdelt_df.copy(True)\n",
    "\n",
    "#Creating Labels. i.e. if change in spx_return is x standard deviations\n",
    "security_prices = my_query.query_yahoo()\n",
    "security_return = np.log(security_prices['Adj Close']).diff() #log Return\n",
    "security_vol = security_return.rolling(window=lookback_window).std().dropna()\n",
    "security_mean = security_return.rolling(window=lookback_window).mean().dropna()\n",
    "security_vol.name = 'Volatility'\n",
    "security_return = security_return.loc[security_vol.index] #First entry is NAN because of return\n",
    "# day_over_day_diff = np.abs(security_return.diff())#can subtract because of log returns\n",
    "# event_idx = [(np.abs(security_mean)+(security_vol * 3.5)) < np.abs(security_return)]\n",
    "event_idx = [((security_mean + security_vol * number_stdev) < security_return) | ((security_mean - security_vol *number_stdev) > security_return) ]\n",
    "event_idx = np.array(event_idx).astype(int).flatten()\n",
    "event_idx = pd.Series(event_idx,index=security_return.index)\n",
    "print ('Data Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quandl Loaded\n"
     ]
    }
   ],
   "source": [
    "api_key =  'reqa36mksyfgx9BR6r88'\n",
    "wti_co = my_query.query_quandl(\"FRED/DCOILWTICO\",api_key)\n",
    "unemploy = my_query.query_quandl(\"FRED/UNEMPLOY\",api_key)\n",
    "m1v = my_query.query_quandl(\"FRED/M1V\",api_key)\n",
    "m2v = my_query.query_quandl(\"FRED/M2V\",api_key)\n",
    "stressindex = my_query.query_quandl(\"FRED/STLFSI\", api_key)\n",
    "dff = my_query.query_quandl(\"FRED/DFF\",api_key)\n",
    "my_query.set_ticker('^VIX')\n",
    "vix = my_query.query_yahoo()\n",
    "vix = vix['Adj Close']\n",
    "vix.name = 'VIX'\n",
    "print ('Quandl Loaded')\n",
    "\n",
    "#Use GLD as proxy for gold. Better to use the futures but don't have good continuous contracts\n",
    "# my_query.set_ticker('GLD')\n",
    "# gld = my_query.query_yahoo()\n",
    "# gld = gld['Adj Close']\n",
    "\n",
    "#Use Continuous Future of Front month gold contract as gold\n",
    "# gold = my_query.query_quandl(\"SCF/CME_GC1_OR\",api_key)\n",
    "# gold = gold['Settle']\n",
    "# #Use Continuous Future of front month  crude as oil\n",
    "# oil = my_query.query_quandl(\"SCF/ICE_B1_OB\",api_key)\n",
    "# oil = oil['Settle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quandl_others = pd.concat([wti_co,unemploy,m1v,m2v,stressindex,vix,dff],axis=1)\n",
    "quandl_others.columns = ['wit_co','unemploy','m1v','m2v','slsi','vix','dff']\n",
    "quandl_others.ffill(inplace=True)\n",
    "quandl_others.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_ts(series,lookback=lookback_window):\n",
    "    rolling_mean = series.rolling(window=lookback).mean()\n",
    "    rolling_std = series.rolling(window=lookback).std() + .10**3\n",
    "    normalized = (series-rolling_mean)/rolling_std\n",
    "    normalized = normalized.dropna()\n",
    "    return(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling using custom scaler\n"
     ]
    }
   ],
   "source": [
    "#Collapse numerical data into x,y pairs by taking means\n",
    "collapsed = gdelt_df.groupby(by=gdelt_df.index).mean()\n",
    "\n",
    "#Shift data so as only to use yesterday's news for tomorrow's prediction\n",
    "#i.e. we shift forward, using yesterday data as today\n",
    "collapsed_shifted = collapsed.shift(1)\n",
    "quandl_shifted = quandl_others.shift(1)\n",
    "\n",
    "#Scale the data in such a way that we aren't looking forward into the feature\n",
    "print ('Scaling using custom scaler')\n",
    "collapsed_shifted = collapsed_shifted.apply(normalize_ts)\n",
    "quandl_shifted = quandl_shifted.apply(normalize_ts)\n",
    "\n",
    "collapsed_shifted.index = pd.to_datetime(collapsed_shifted.index,format='%Y%m%d')\n",
    "collapsed_shifted = collapsed_shifted.loc[security_vol.index].dropna()\n",
    "collapsed_shifted = pd.concat([collapsed_shifted,quandl_shifted],axis=1)\n",
    "event_idx = event_idx.dropna()\n",
    "collapsed_shifted = collapsed_shifted.loc[event_idx.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train test split...\n"
     ]
    }
   ],
   "source": [
    "print ('Creating train test split...')\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(collapsed_shifted,event_idx,stratify=None,test_size=.20,shuffle=False)\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(X_train,Y_train,test_size=.20,stratify=None,shuffle=False)\n",
    "\n",
    "#Creating Copies of Data Frames these will be useful later for debugging\n",
    "X_train_df = X_train.copy(True)\n",
    "Y_train_df = Y_train.copy(True)\n",
    "Y_val_df = Y_val.copy(True)\n",
    "X_train  = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train before smote\n",
      "2780\n",
      "Number of Positives before smote\n",
      "11\n",
      "Performing Oversampling/Undersampling...\n",
      "Length of X_train after smote\n",
      "5482\n",
      "Number of Positive samples after smote\n",
      "2769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pca = PCA(whiten=True)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_val = pca.transform(X_val)\n",
    "\n",
    "print ('Length of X_train before smote')\n",
    "print (len(X_train))\n",
    "print ('Number of Positives before smote')\n",
    "print (Y_train.sum())\n",
    "\n",
    "\n",
    "print ('Performing Oversampling/Undersampling...')\n",
    "s = SMOTEENN()\n",
    "X_train,Y_train= s.fit_sample(X_train,Y_train)\n",
    "\n",
    "print ('Length of X_train after smote')\n",
    "print (len(X_train))\n",
    "\n",
    "print ('Number of Positive samples after smote')\n",
    "print (Y_train.sum())\n",
    "\n",
    "# print ('Proportion after smote {}'.format(sum(Y_train)/len(Y_train))\n",
    "\n",
    "\n",
    "# X_train = X_train.reshape(-1,X_train.shape[1],1)\n",
    "# X_test = X_test.reshape(-1,X_test.shape[1],1)\n",
    "# X_val = X_val.reshape(-1,X_val.shape[1],1)\n",
    "# print ('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edward Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.keras as k\n",
    "import tensorflow.contrib.slim as slim\n",
    "from edward.models import BernoulliWithSigmoidProbs,StudentT,Normal,Categorical,Bernoulli,Empirical,Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "D = X_train.shape[1]\n",
    "Y_val = Y_val\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.int32)\n",
    "Y_val = Y_val.astype(np.int32)\n",
    "features = {'x':X_train}\n",
    "drop_rate = 0.35\n",
    "\n",
    "X_train = X_train.reshape(-1,D,1)\n",
    "Y_train = Y_train.reshape(-1,1)\n",
    "\n",
    "\n",
    "X_val = X_val.reshape(-1,D,1)\n",
    "Y_val = Y_val.reshape(-1,1)\n",
    "\n",
    "\n",
    "X_val = X_val.reshape(-1,D,1)\n",
    "Y_val = Y_val.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Had to use a separate function couldn't get TF GPU to work with TF 1.4.0\n",
    "#Taken from \n",
    "\n",
    "def max_out(inputs, num_units, axis=None):\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    if shape[0] is None:\n",
    "        shape[0] = -1\n",
    "    if axis is None:  # Assume that channel is the last dimension\n",
    "        axis = -1\n",
    "    num_channels = shape[axis]\n",
    "    if num_channels % num_units:\n",
    "        raise ValueError('number of features({}) is not '\n",
    "                         'a multiple of num_units({})'.format(num_channels, num_units))\n",
    "    shape[axis] = num_units\n",
    "    shape += [num_channels // num_units]\n",
    "    outputs = tf.reduce_max(tf.reshape(inputs, shape), -1, keep_dims=False)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 128\n",
    "\n",
    "TEST_BATCH_SIZE = TRAIN_BATCH_SIZE\n",
    "N_classes = 1\n",
    "N = len(X_train)\n",
    "N_VAL = len(X_val)\n",
    "N_TEST = len(X_test)\n",
    "VAL_BATCH_SIZE = N_VAL\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, X_train.shape[1],1],name='Input')\n",
    "labels = tf.placeholder(tf.int32,[None],name='labels')\n",
    "is_training = tf.placeholder(tf.bool,name='training_flag')\n",
    "input_val = tf.placeholder(tf.float32,[N_VAL,X_val.shape[1],1],name='val_input')\n",
    "label_val = tf.placeholder(tf.int32,[N_VAL,1],name='val_label')\n",
    "\n",
    "\n",
    "train_dataset = tf.contrib.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "train_dataset = train_dataset.batch(TRAIN_BATCH_SIZE)\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "\n",
    "val_dataset = tf.contrib.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "val_dataset = val_dataset.batch(VAL_BATCH_SIZE)\n",
    "val_iterator = val_dataset.make_initializable_iterator()\n",
    "\n",
    "\n",
    "test_dataset = tf.contrib.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "test_dataset = test_dataset.batch(TEST_BATCH_SIZE)\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nh1 = 1024\n",
    "nh2 = 512\n",
    "nh3 = 256\n",
    "df = 10000.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/keras/legacy/layers.py:527: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `MaxoutDense` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THIS MODEL\n"
     ]
    }
   ],
   "source": [
    "def tf_model_with_edward(my_inputs,is_training):\n",
    "        conv1_w = StudentT(loc=tf.zeros([1,1,nh1]), scale=tf.ones([1,1,nh1]),df=df)\n",
    "        conv1_b = StudentT(loc=tf.zeros([nh1]), scale=tf.ones([nh1]),df=df)\n",
    "        net = tf.nn.conv1d(my_inputs,conv1_w,stride=5,padding='SAME')\n",
    "        net = net + conv1_b\n",
    "        net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "        net  = tf.layers.dropout(net,training=is_training,rate=drop_rate)\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        conv2_w = StudentT(loc=tf.zeros([1,nh1,nh1]), scale=tf.ones([1,nh1,nh1]),df=df)\n",
    "        conv2_b = StudentT(loc=tf.zeros([nh1]), scale=tf.ones([nh1]),df=df)\n",
    "        net = tf.nn.conv1d(net,conv2_w,stride=5, padding='SAME')\n",
    "        net = net + conv2_b\n",
    "        net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "        net  = tf.layers.dropout(net,training=is_training,rate=drop_rate)\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        conv3_w = StudentT(loc=tf.zeros([1,nh1,nh2]), scale=tf.ones([1,nh1,nh2]),df=df)\n",
    "        conv3_b = StudentT(loc=tf.zeros([nh2]), scale=tf.ones([nh2]),df=df)\n",
    "        net = tf.nn.conv1d(net,conv3_w,stride=5, padding='SAME')\n",
    "        net = net + conv3_b\n",
    "        net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "        net  = tf.layers.dropout(net,training=is_training,rate=drop_rate)\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        conv1a_w = StudentT(loc=tf.zeros([1,nh2,nh3]), scale=tf.ones([1,nh2,nh3]),df=df)\n",
    "        conv1a_b = StudentT(loc=tf.zeros([nh3]), scale=tf.ones([nh3]),df=df)\n",
    "        net = tf.nn.conv1d(net,conv1a_w,stride=3, padding='SAME')\n",
    "        net = net + conv1a_b\n",
    "        net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "        net  = tf.layers.dropout(net,training=is_training,rate=drop_rate)\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        conv2a_w = StudentT(loc=tf.zeros([1,nh3,nh3]), scale=tf.ones([1,nh3,nh3]),df=df)\n",
    "        conv2a_b = StudentT(loc=tf.zeros([nh3]), scale=tf.ones([nh3]),df=df)\n",
    "        net = tf.nn.conv1d(net,conv2a_w, stride=3,padding='SAME')\n",
    "        net = net + conv2a_b\n",
    "        net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "        net  = tf.layers.dropout(net,training=is_training,rate=drop_rate)\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        conv3a_w = StudentT(loc=tf.zeros([1,nh3,nh3]), scale=tf.ones([1,nh3,nh3]),df=df)\n",
    "        conv3a_b = StudentT(loc=tf.zeros([nh3]), scale=tf.ones([nh3]),df=df)\n",
    "        net = tf.nn.conv1d(net,conv3a_w,stride=3, padding='SAME')\n",
    "        net = net + conv3a_b\n",
    "        net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "        net  = tf.layers.dropout(net,training=is_training,rate=.35)\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        \n",
    "        conv4a_w = StudentT(loc=tf.zeros([1,nh3,nh3]), scale=tf.ones([1,nh3,nh3]),df=df)\n",
    "        conv4a_b = StudentT(loc=tf.zeros([nh3]), scale=tf.ones([nh3]),df=df)\n",
    "        net = tf.nn.conv1d(net,conv4a_w,stride=3, padding='SAME')\n",
    "        net = net + conv4a_b\n",
    "        net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "        net  = tf.layers.dropout(net,training=is_training,rate=.35)\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        \n",
    "        conv5a_w = StudentT(loc=tf.zeros([1,nh3,nh3]), scale=tf.ones([1,nh3,nh3]),df=df)\n",
    "        conv5a_b = StudentT(loc=tf.zeros([nh3]), scale=tf.ones([nh3]),df=df)\n",
    "        net = tf.nn.conv1d(net,conv5a_w,stride=3, padding='SAME')\n",
    "        net = net + conv5a_b\n",
    "        net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "        net  = tf.layers.dropout(net,training=is_training,rate=.35)\n",
    "        net = tf.nn.relu(net)\n",
    "#         net = tf.concat([net,net],axis=1)\n",
    "        \n",
    "        flatten = tf.contrib.layers.flatten(inputs=net)\n",
    "\n",
    "        net = keras.layers.MaxoutDense(1024)(flatten)\n",
    "        net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)     \n",
    "        net = keras.layers.MaxoutDense(512)(net)\n",
    "        net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "        net = keras.layers.MaxoutDense(256)(net)\n",
    "        net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "        net = tf.layers.dense(net,2,activation=tf.nn.softmax)\n",
    "\n",
    "        predicted_mask = Categorical(net)\n",
    "        \n",
    "        \n",
    "        conv1_qw = Normal(loc=tf.Variable(tf.random_normal([1,1,nh1])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([1,1,nh1]))))\n",
    "        conv1_qb = Normal(loc=tf.Variable(tf.random_normal([nh1])),\n",
    "                              scale=tf.nn.softplus(tf.Variable(tf.random_normal([nh1]))))\n",
    "        conv2_qw = Normal(loc=tf.Variable(tf.random_normal([1,nh1,nh1])), \n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([1,nh1,nh1]))))\n",
    "        conv2_qb = Normal(loc=tf.Variable(tf.random_normal([nh1])),\n",
    "                              scale=tf.nn.softplus(tf.Variable(tf.random_normal([nh1]))))\n",
    "\n",
    "        conv3_qw = Normal(loc=tf.Variable(tf.random_normal([1,nh1,nh2])), \n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([1,nh1,nh2]))))\n",
    "        conv3_qb = Normal(loc=tf.Variable(tf.random_normal([nh2])),\n",
    "                              scale=tf.nn.softplus(tf.Variable(tf.random_normal([nh2]))))\n",
    "\n",
    "\n",
    "        conv1a_qw = Normal(loc=tf.Variable(tf.random_normal([1,nh2,nh3])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([1,nh2,nh3]))))\n",
    "        conv1a_qb = Normal(loc=tf.Variable(tf.random_normal([nh3])),\n",
    "                              scale=tf.nn.softplus(tf.Variable(tf.random_normal([nh3]))))\n",
    "        conv2a_qw = Normal(loc=tf.Variable(tf.random_normal([1,nh3,nh3])), \n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([1,nh3,nh3]))))\n",
    "        conv2a_qb = Normal(loc=tf.Variable(tf.random_normal([nh3])),\n",
    "                              scale=tf.nn.softplus(tf.Variable(tf.random_normal([nh3]))))\n",
    "\n",
    "        conv3a_qw = Normal(loc=tf.Variable(tf.random_normal([1,nh3,nh3])), \n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([1,nh3,nh3]))))\n",
    "        conv3a_qb = Normal(loc=tf.Variable(tf.random_normal([nh3])),\n",
    "                              scale=tf.nn.softplus(tf.Variable(tf.random_normal([nh3]))))\n",
    "        \n",
    "        \n",
    "        conv4a_qw = Normal(loc=tf.Variable(tf.random_normal([1,nh3,nh3])), \n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([1,nh3,nh3]))))\n",
    "        conv4a_qb = Normal(loc=tf.Variable(tf.random_normal([nh3])),\n",
    "                              scale=tf.nn.softplus(tf.Variable(tf.random_normal([nh3]))))\n",
    "        \n",
    "        \n",
    "        conv5a_qw = Normal(loc=tf.Variable(tf.random_normal([1,nh3,nh3])), \n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([1,nh3,nh3]))))\n",
    "        conv5a_qb = Normal(loc=tf.Variable(tf.random_normal([nh3])),\n",
    "                              scale=tf.nn.softplus(tf.Variable(tf.random_normal([nh3]))))\n",
    "        \n",
    "        \n",
    "        latent_dict = {\n",
    "                   conv1_w:conv1_qw,conv1_b:conv1_qb, \n",
    "                   conv1a_w:conv1a_qw,conv1a_b:  conv1a_qb,\n",
    "                   conv2_w: conv2_qw, conv2_b:  conv2_qb, \n",
    "                   conv2a_w:conv2a_qw,conv2a_b:  conv2a_qb,\n",
    "                   conv3_w:conv3_qw, conv3_b:  conv3_qb, \n",
    "                   conv3a_w:conv3a_qw, conv3a_b:  conv3a_qb,\n",
    "                   conv4a_w:conv4a_qw, conv4a_b:conv4a_qb,\n",
    "                   conv5a_w:conv5a_qw, conv5a_b:conv5a_qb\n",
    "#                    last_w:last_qw, last_b:last_qb    \n",
    "                  }\n",
    "    \n",
    "        print ('RUNNING THIS MODEL')\n",
    "        return predicted_mask, latent_dict\n",
    "\n",
    "\n",
    "predicted_mask, latent_dict = tf_model_with_edward(inputs, is_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inference(predicted_mask, latent_dict, labels, n_epoch=5,session_dir='tmp/inference',restore_sess=False):\n",
    "    n_batch = int(N/TRAIN_BATCH_SIZE)\n",
    "    loss = []\n",
    "    if restore_sess:\n",
    "        sess = ed.get_session()\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, session_dir)\n",
    "        return\n",
    "    else:\n",
    "        inference = ed.KLqp(latent_dict,data={predicted_mask:labels})\n",
    "        inference.initialize(n_iter=n_batch*n_epoch, scale={predicted_mask: N/TRAIN_BATCH_SIZE})\n",
    "        saver = tf.train.Saver()\n",
    "        sess = ed.get_session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(train_iterator.initializer)\n",
    "        for i in range(inference.n_iter):\n",
    "            train_data, train_labels =sess.run(train_iterator.get_next())\n",
    "            if len(train_data) < TRAIN_BATCH_SIZE:\n",
    "                sess.run(train_iterator.initializer)\n",
    "                train_data,train_labels = sess.run(train_iterator.get_next())\n",
    "            train_labels = train_labels.flatten()\n",
    "#             train_labels = train_labels.reshape(-1,2)\n",
    "#             ohc  = OneHotEncoder(2)\n",
    "#             train_labels = ohc.fit_transform(train_labels).toarray()\n",
    "            info_dict = inference.update({inputs: train_data, labels: train_labels, is_training: True})\n",
    "            inference.print_progress(info_dict)\n",
    "            loss.append(info_dict['loss'])\n",
    "#         saver.save(sess, session_dir)\n",
    "        loss = np.array(loss)\n",
    "        plt.plot(loss[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [100%] ██████████████████████████████ Elapsed: 89s | Loss: 85661.000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSMIUGiIikrD/D3ObEhwWqvYSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29c4debc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference(predicted_mask, latent_dict, labels, session_dir='checkpoints/edward_test',restore_sess=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def criticism(predicted_mask,latent_dict):\n",
    "    predicted_mask_post2 = ed.copy(predicted_mask, latent_dict)\n",
    "    sess=ed.get_session()\n",
    "    num_samples = 500\n",
    "#     pred = predicted_mask_post2.eval(feed_dict={inputs:X_val,is_training:True})\n",
    "#     pred = sess.run(predicted_mask_post2, feed_dict={inputs:X_val,is_training:True})\n",
    "    acc = [accuracy_score(Y_val,sess.run(predicted_mask_post2, feed_dict={inputs:X_val,is_training:True})) \n",
    "             for _ in range(num_samples)] \n",
    "    prec = [precision_score(Y_val,sess.run(predicted_mask_post2, feed_dict={inputs:X_val,is_training:True})) \n",
    "             for _ in range(num_samples)]\n",
    "    rec = [recall_score(Y_val,sess.run(predicted_mask_post2, feed_dict={inputs:X_val,is_training:True})) \n",
    "             for _ in range(num_samples)]\n",
    "\n",
    "    roc = [roc_auc_score(Y_val,sess.run(predicted_mask_post2, feed_dict={inputs:X_val,is_training:True})) \n",
    "             for _ in range(num_samples)]\n",
    "    f1 = [f1_score(Y_val,sess.run(predicted_mask_post2, feed_dict={inputs:X_val,is_training:True})) \n",
    "             for _ in range(num_samples)]\n",
    "\n",
    "    return(np.array(acc),\n",
    "           np.array(prec),\n",
    "           np.array(rec),\n",
    "           np.array(roc),\n",
    "           np.array(f1))\n",
    "acc,prec,rec,roc,f1 = criticism(predicted_mask,latent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def criticism2(predicted_mask, latent_dict, data_iterator, num_samples, ppc_nsamples=500):\n",
    "    predicted_mask_post = ed.copy(predicted_mask, latent_dict)\n",
    "    predicted_mask_post_samples = predicted_mask_post.sample(ppc_nsamples)\n",
    "    sess = ed.get_session()\n",
    "    sess.run(data_iterator.initializer)\n",
    "    num_batches = num_samples // VAL_BATCH_SIZE\n",
    "    for i in range(num_batches):\n",
    "        data, labels = sess.run(data_iterator.get_next())\n",
    "        labels = labels.flatten()\n",
    "        ppc=sess.run(predicted_mask_post_samples,\n",
    "                 feed_dict={inputs: data, predicted_mask: labels, is_training: True})\n",
    "    return (ppc)\n",
    "ppc = criticism2(predicted_mask,latent_dict,val_iterator,len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   4.,   10.,   33.,   76.,  111.,  108.,   87.,   55.,   12.,    4.]),\n",
       " array([ 0.67338129,  0.68359712,  0.69381295,  0.70402878,  0.7142446 ,\n",
       "         0.72446043,  0.73467626,  0.74489209,  0.75510791,  0.76532374,\n",
       "         0.77553957]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40a7803588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_list = []\n",
    "for i in range(len(ppc)):\n",
    "    acc_list.append(accuracy_score(Y_val,ppc[i]))\n",
    "plt.hist(np.array(acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2.,    2.,   35.,   80.,  108.,  142.,   78.,   36.,   15.,    2.]),\n",
       " array([ 0.63021583,  0.64201439,  0.65381295,  0.66561151,  0.67741007,\n",
       "         0.68920863,  0.70100719,  0.71280576,  0.72460432,  0.73640288,\n",
       "         0.74820144]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29d961c9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 184.,    0.,    0.,  215.,    0.,    0.,   94.,    0.,    0.,    7.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDL0kNWfoJak5Qy9JzRl6SWru/wDEDimGriIT0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2994766ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 145.,    0.,   28.,  200.,    0.,   23.,   81.,    8.,    3.,   12.]),\n",
       " array([ 0.        ,  0.00288462,  0.00576923,  0.00865385,  0.01153846,\n",
       "         0.01442308,  0.01730769,  0.02019231,  0.02307692,  0.02596154,\n",
       "         0.02884615]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSFLjDAJJapxBIEmNMwgkqXH/DwIeqFslT9beAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29946bce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 161.,    0.,    0.,  216.,    1.,    0.,  108.,    1.,    0.,   13.]),\n",
       " array([ 0.31936416,  0.37348266,  0.42760116,  0.48171965,  0.53583815,\n",
       "         0.58995665,  0.64407514,  0.69819364,  0.75231214,  0.80643064,\n",
       "         0.86054913]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktScoZek5v4Ho5Q34cAo8uwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29946a3860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## No Edward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.reshape(-1,X_train.shape[1],1)\n",
    "X_test = X_test.reshape(-1,X_test.shape[1],1)\n",
    "X_val = X_val.reshape(-1,X_val.shape[1],1)\n",
    "D = X_train.shape[1]\n",
    "Y_val = Y_val\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.int32)\n",
    "Y_val = Y_val.astype(np.int32)\n",
    "features = {'x':X_train}\n",
    "drop_rate = .55\n",
    "\n",
    "\n",
    "Y_train = Y_train.flatten()\n",
    "Y_val = Y_val.flatten()\n",
    "Y_test = np.array(Y_test).flatten()\n",
    "nh1 = 512.0\n",
    "nh2 = 256.0\n",
    "nh3 = 128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5482, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmplql71yjf\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_tf_random_seed': 1, '_session_config': None, '_save_checkpoints_secs': 600, '_model_dir': '/tmp/tmplql71yjf', '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/keras/legacy/layers.py:527: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `MaxoutDense` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmplql71yjf/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.988244, step = 1\n",
      "INFO:tensorflow:global_step/sec: 23.8612\n",
      "INFO:tensorflow:loss = 0.655306, step = 101 (4.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7908\n",
      "INFO:tensorflow:loss = 0.293596, step = 201 (3.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8254\n",
      "INFO:tensorflow:loss = 0.179726, step = 301 (3.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.568\n",
      "INFO:tensorflow:loss = 0.168775, step = 401 (3.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7686\n",
      "INFO:tensorflow:loss = 0.0636823, step = 501 (3.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7114\n",
      "INFO:tensorflow:loss = 0.14321, step = 601 (3.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7348\n",
      "INFO:tensorflow:loss = 0.0108004, step = 701 (3.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.578\n",
      "INFO:tensorflow:loss = 0.0110254, step = 801 (3.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5185\n",
      "INFO:tensorflow:loss = 0.0271826, step = 901 (3.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6527\n",
      "INFO:tensorflow:loss = 0.0113463, step = 1001 (3.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7919\n",
      "INFO:tensorflow:loss = 0.157739, step = 1101 (3.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.703\n",
      "INFO:tensorflow:loss = 0.00804046, step = 1201 (3.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6431\n",
      "INFO:tensorflow:loss = 0.0181742, step = 1301 (3.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.754\n",
      "INFO:tensorflow:loss = 0.000275685, step = 1401 (3.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5811\n",
      "INFO:tensorflow:loss = 0.00316931, step = 1501 (3.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7646\n",
      "INFO:tensorflow:loss = 0.0163636, step = 1601 (3.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6577\n",
      "INFO:tensorflow:loss = 0.000230608, step = 1701 (3.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6637\n",
      "INFO:tensorflow:loss = 0.0015852, step = 1801 (3.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6469\n",
      "INFO:tensorflow:loss = 0.00107976, step = 1901 (3.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5703\n",
      "INFO:tensorflow:loss = 0.050556, step = 2001 (3.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6294\n",
      "INFO:tensorflow:loss = 0.0380689, step = 2101 (3.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5426\n",
      "INFO:tensorflow:loss = 0.00218834, step = 2201 (3.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4605\n",
      "INFO:tensorflow:loss = 0.00589671, step = 2301 (3.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5207\n",
      "INFO:tensorflow:loss = 0.0285133, step = 2401 (3.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5635\n",
      "INFO:tensorflow:loss = 0.00969116, step = 2501 (3.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6179\n",
      "INFO:tensorflow:loss = 0.00290284, step = 2601 (3.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5158\n",
      "INFO:tensorflow:loss = 0.0049341, step = 2701 (3.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4825\n",
      "INFO:tensorflow:loss = 0.000318732, step = 2801 (3.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6777\n",
      "INFO:tensorflow:loss = 0.00051996, step = 2901 (3.894 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/tmplql71yjf/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000303375.\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-13-04:11:34\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmplql71yjf/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-13-04:11:36\n",
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 0.82446, global_step = 3000, loss = 4.09726\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmplql71yjf/model.ckpt-3000\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def tf_model(features,labels,mode):       \n",
    "        if tf.estimator.ModeKeys.TRAIN == 'train':\n",
    "            is_training=True\n",
    "        else:\n",
    "            is_training = False\n",
    "    \n",
    "    \n",
    "        layer1 =  tf.layers.conv1d(inputs=features['x'],name='x',filters=512,kernel_size=5,padding='same',\n",
    "                                                       activation=tf.nn.relu,kernel_initializer=k.initializers.he_normal())\n",
    "        layer1 =  tf.contrib.layers.batch_norm(layer1, is_training=is_training, decay=0.999)\n",
    "        layer1 = tf.layers.dropout(inputs=layer1,training=is_training,rate=drop_rate)\n",
    "\n",
    "        layer1 =  tf.layers.conv1d(inputs=layer1,filters=512,kernel_size=5,padding='same',\n",
    "                                                       activation=tf.nn.relu,kernel_initializer=k.initializers.he_normal())\n",
    "        layer1 =  tf.contrib.layers.batch_norm(layer1, is_training=is_training, decay=0.999)\n",
    "        layer1 = tf.layers.dropout(inputs=layer1,training=is_training,rate=.55)\n",
    "\n",
    "        \n",
    "        layer2 =  tf.layers.conv1d(layer1,filters=256,kernel_size=5,padding='same',\n",
    "                                   activation=tf.nn.relu,kernel_initializer=k.initializers.he_normal())\n",
    "        layer2 =  tf.contrib.layers.batch_norm(layer2, is_training=is_training, decay=0.999)\n",
    "        layer2 = tf.layers.dropout(inputs=layer2,training=is_training,rate=.55)\n",
    "\n",
    "\n",
    "        layer3 =  tf.layers.conv1d(layer2,filters=128,kernel_size=5,padding='same',activation=tf.nn.relu,kernel_initializer=k.initializers.he_normal())\n",
    "        layer3 =  tf.contrib.layers.batch_norm(layer3, is_training=is_training, decay=0.999)\n",
    "        layer3 = tf.layers.dropout(inputs=layer1,training=is_training,rate=.55)\n",
    "\n",
    "\n",
    "        layer4 =  tf.layers.conv1d(layer3,filters=128,kernel_size=3,padding='same',activation=tf.nn.relu,kernel_initializer=k.initializers.he_normal())\n",
    "        layer4 =  tf.contrib.layers.batch_norm(layer4, is_training=is_training, decay=0.999)\n",
    "        layer4 = tf.layers.dropout(inputs=layer4,training=is_training,rate=.35)\n",
    "\n",
    "\n",
    "        layer5 =  tf.layers.conv1d(layer4,filters=128,kernel_size=3,padding='same',activation=tf.nn.relu,kernel_initializer=k.initializers.he_normal())\n",
    "        layer5 =  tf.contrib.layers.batch_norm(layer5, is_training=is_training, decay=0.999)\n",
    "        layer5 = tf.layers.dropout(inputs=layer5,training=is_training,rate=.35)\n",
    "\n",
    "\n",
    "        layer6 =  tf.layers.conv1d(layer5,filters=128,kernel_size=3,padding='same',activation=tf.nn.relu,kernel_initializer=k.initializers.he_normal())\n",
    "        layer6 =  tf.contrib.layers.batch_norm(layer6, is_training=is_training, decay=0.999)\n",
    "        layer6 = tf.layers.dropout(inputs=layer6,training=is_training,rate=.35)\n",
    "\n",
    "        layer6 =  tf.layers.conv1d(layer6,filters=128,kernel_size=3,padding='same',activation=tf.nn.relu,kernel_initializer=k.initializers.he_normal())\n",
    "        layer6 =  tf.contrib.layers.batch_norm(layer6, is_training=is_training, decay=0.999)\n",
    "        layer6 = tf.layers.dropout(inputs=layer6,training=is_training,rate=.35)\n",
    "\n",
    "        flatten = tf.contrib.layers.flatten(inputs=layer6)\n",
    "        \n",
    "#         layer7 = tf.layers.dense(flatten,1024)\n",
    "#         layer7 =  max_out(layer7,1024)\n",
    "#         layer7 = tf.layers.dense(layer7,1024,activation=tf.nn.relu)\n",
    "#         layer7 =  tf.contrib.layers.batch_norm(layer7, is_training=is_training, decay=0.999)\n",
    "    #     layer7 = tf.layers.dropout(inputs=layer7,training=is_training,rate=drop_rate)\n",
    "\n",
    "        layer8 = keras.layers.MaxoutDense(1024)(flatten)\n",
    "        layer8 =  tf.contrib.layers.batch_norm(layer8, is_training=is_training, decay=0.999)\n",
    "        \n",
    "        layer9 = keras.layers.MaxoutDense(512)(layer8)\n",
    "        layer9 =  tf.contrib.layers.batch_norm(layer9, is_training=is_training, decay=0.999)\n",
    "        \n",
    "        layer10 = keras.layers.MaxoutDense(256)(layer9)\n",
    "        layer10 =  tf.contrib.layers.batch_norm(layer10, is_training=is_training, decay=0.999)\n",
    "\n",
    "\n",
    "        logits = tf.layers.dense(layer10,units=2)\n",
    "        \n",
    "\n",
    "        predictions = {\n",
    "          \"classes\": tf.argmax(input=logits, axis=1),\n",
    "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "            }\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "          # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "        ohc =  tf.one_hot(indices=tf.cast(labels, tf.int32), depth=2)\n",
    "        loss = tf.losses.softmax_cross_entropy(onehot_labels=ohc, logits=logits)\n",
    "\n",
    "        # Configure the Training Op (for TRAIN mode)\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "            train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "        # Add evaluation metrics (for EVAL mode)\n",
    "        eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels=labels, predictions=predictions[\"classes\"])}\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "my_classifier = tf.estimator.Estimator(\n",
    "    model_fn=tf_model)\n",
    "    \n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\":X_train},\n",
    "      y=np.array(Y_train).flatten(),\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_val},\n",
    "    y=Y_val,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "my_classifier.train(input_fn=train_input_fn, steps=3000)\n",
    "eval_results = my_classifier.evaluate(input_fn=eval_input_fn)\n",
    "\n",
    "predictions = list(my_classifier.predict(input_fn=eval_input_fn))\n",
    "predicted_classes = [p[\"classes\"] for p in predictions]\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Standard Deviations: 3.5\n",
      " Accuracy: 0.8244604316546763\n",
      " F1: 0.03174603174603175\n",
      " RoC: 0.7459055876685934\n",
      " Precision: 0.016260162601626018\n",
      " Recall: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "acc = accuracy_score(Y_val,predicted_classes)\n",
    "f1 = f1_score(Y_val,predicted_classes)\n",
    "roc = roc_auc_score(Y_val,predicted_classes)\n",
    "prec = precision_score(Y_val,predicted_classes)\n",
    "recall= recall_score(Y_val,predicted_classes)\n",
    "\n",
    "\n",
    "print (' Standard Deviations: {}'.format(number_stdev))\n",
    "print (' Accuracy: {}'.format(acc))\n",
    "print (' F1: {}'.format(f1))\n",
    "print (' RoC: {}'.format(roc))\n",
    "print (' Precision: {}'.format(prec))\n",
    "print (' Recall: {}'.format(recall))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
