{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Off-the-shelf Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Query as query\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline as imb_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "Given a more formal defintion to \"market event\" can we proceed to forecast\n",
    "using the standard indicators in the gdelt events database using some simple off-the-shelf methods. This is to be seen as the \"litmus test\" for the project, a first test to get a feel for the possible modeling challenges and effectiveness of our standard methods.\n",
    "\n",
    "## Market Event Definition:\n",
    "SP500 up/down 1.5 standard deviations measured by rolling historical daily \n",
    "volatility  over preceeding one month period. This is a classification \n",
    "problem. Can be extended to more sophisticated time series estimate or \n",
    "thresholding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "After you've queried the database once, say on your first run, then set this to True so you don't query it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = False\n",
    "gdelt_df = pd.read_csv('Gdelt_events_20160101_20171006.csv')\n",
    "gdelt_df = gdelt_df.set_index('sqldate',drop=True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj_id = 'capstone-v0'\n",
    "start_date = '2016-01-01'\n",
    "end_date = '2017-10-06'\n",
    "ticker = '^GSPC'\n",
    "my_query = query.query_tool(proj_id,start_date,end_date,ticker)\n",
    "sql_query = \"\"\"\n",
    "            SELECT Actor1Name, Actor2Name, GoldsteinScale,NumMentions,sourceurl,\n",
    "            sqldate, avgtone, numarticles, numsources,  \n",
    "            FROM [gdelt-bq:full.events] \n",
    "            WHERE sqldate > 20160101 and sqldate <= 20171006  and \n",
    "                Actor1Geo_CountryCode like \"%US%\" and \n",
    "                Actor1Code like \"%BUS%\"\n",
    "            \"\"\"\n",
    "if load_data == False:\n",
    "    my_query.query_gdelt(sql_query)\n",
    "    my_query.gdelt_df = my_query.gdelt_df.set_index('sqldate',drop=True).sort_index()\n",
    "    df = my_query.gdelt_df.copy(True)\n",
    "    my_query.save_gdelt_df('Gdelt_events_20160101_20171006')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Labels:\n",
    "i.e. If SP500 up/down 1.5 standard deviations then consider that an \"event\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spx_prices = my_query.query_yahoo()\n",
    "spx_return = np.log(spx_prices['Adj Close']).diff() #log Return\n",
    "spx_vol = spx_return.rolling(window=20).std().dropna()\n",
    "spx_return = spx_return.loc[spx_vol.index] #First entry is NAN because of return\n",
    "day_over_day_diff = np.abs(spx_return.diff())#can subtract because of log returns\n",
    "event_idx = [spx_vol*1.5 < day_over_day_diff]\n",
    "event_idx = np.array(event_idx).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Vectors from GDELT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collapsed = gdelt_df.groupby(by=gdelt_df.index).sum()\n",
    "collapsed.index = pd.to_datetime(collapsed.index,format='%Y%m%d')\n",
    "collapsed = collapsed.loc[spx_vol.index].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models : Gradient Boosted Trees / Support Vector Machine\n",
    "\n",
    "Considerations:\n",
    "\n",
    "1.) Inbalanced Data - So using SMOTE\n",
    "\n",
    "2.) \"Small\" sized dataset - so leveraging the Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC Accuracy: 0.5887850467289719\n",
      "GBC F1: 0.35294117647058815\n",
      "GBC RoC: 0.5509756097560976\n",
      "SVC Accuracy: 0.5514018691588785\n",
      "SVC F1: 0.3142857142857143\n",
      "SVC RoC: 0.5126829268292683\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(collapsed,event_idx,shuffle=False)\n",
    "pipeline = imb_pipeline(PolynomialFeatures(3),StandardScaler(),SMOTE(),GradientBoostingClassifier())\n",
    "param_grid = {'gradientboostingclassifier__n_estimators':[100,500,1000,3000],\n",
    "              'gradientboostingclassifier__max_depth':[1,3,5]}\n",
    "cv_svc = GridSearchCV(pipeline,param_grid=param_grid)\n",
    "cv_svc.fit(X_train,Y_train)\n",
    "pred = cv_svc.predict(X_test)\n",
    "acc = accuracy_score(Y_test,pred)\n",
    "f1 = f1_score(Y_test,pred)\n",
    "roc = roc_auc_score(Y_test,pred)\n",
    "\n",
    "print ('GBC Accuracy: {}'.format(acc))\n",
    "print ('GBC F1: {}'.format(f1))\n",
    "print ('GBC RoC: {}'.format(roc))\n",
    "\n",
    "pipeline = imb_pipeline(PolynomialFeatures(3),StandardScaler(),SMOTE(),SVC())\n",
    "param_grid = {'svc__C':[0.5,1,100,500,1000]}\n",
    "cv_svc = GridSearchCV(pipeline,param_grid=param_grid)\n",
    "cv_svc.fit(X_train,Y_train)\n",
    "pred = cv_svc.predict(X_test)\n",
    "acc = accuracy_score(Y_test,pred)\n",
    "f1 = f1_score(Y_test,pred)\n",
    "roc = roc_auc_score(Y_test,pred)\n",
    "\n",
    "print ('SVC Accuracy: {}'.format(acc))\n",
    "print ('SVC F1: {}'.format(f1))\n",
    "print ('SVC RoC: {}'.format(roc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Comparison of prediction vs truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pred</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Truth</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...   97   98   99   \\\n",
       "Pred     0    1    1    0    0    1    0    0    0    1 ...     0    1    0   \n",
       "Truth    0    0    0    0    0    1    0    1    1    0 ...     0    0    0   \n",
       "\n",
       "       100  101  102  103  104  105  106  \n",
       "Pred     1    1    0    0    0    0    0  \n",
       "Truth    0    0    0    0    0    0    1  \n",
       "\n",
       "[2 rows x 107 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.DataFrame([pred,Y_test],index=['Pred','Truth'])\n",
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criticism\n",
    "\n",
    "The results leave much to be desired. In fact if we just predicted the most probable class (0) we'd get around 80% accuracy, but that isn't useful to us. But we should be happy with this result, this proves this is  a challenging modeling problem that can't be solved immediately with  off-the-shelf methods. We'd have to employ something clever. Next steps are: Voting Ensembles, more feature engineering/selection/discovery, and a more sophisticated metric of \"event\" . As our mentors have stated they want to stay with traditional ML if possible, and use interpretable models.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
