{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance -- Deeplift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and perpare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# np.random.seed(12345) # Set seed\n",
    "\n",
    "import pandas as pd\n",
    "from imblearn.combine import SMOTEENN \n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import resample\n",
    "from keras.layers import Dense,BatchNormalization,Input,Convolution1D,GRU,Dropout\n",
    "#from keras.models import Model\n",
    "import keras\n",
    "#import pdb\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,recall_score,precision_score\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import deeplift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data obtained earlier using Michael's code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_shifted = pd.read_csv('collapsed_shifted.csv',index_col=0)\n",
    "event_idx = pd.read_csv('event_idx.csv',header=None,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train test split...\n"
     ]
    }
   ],
   "source": [
    "print ('Creating train test split...')\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(collapsed_shifted,event_idx,stratify=None,test_size=.20,shuffle=False)\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(X_train,Y_train,test_size=.20,stratify=None,shuffle=False)\n",
    "\n",
    "#Creating Copies of Data Frames these will be useful later for debugging\n",
    "X_train_df = X_train.copy(True)\n",
    "Y_train_df = Y_train.copy(True)\n",
    "Y_val_df = Y_val.copy(True)\n",
    "X_train  = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train before smote\n",
      "2780\n",
      "Number of Positives before smote\n",
      "1    166\n",
      "dtype: int64\n",
      "Performing Oversampling/Undersampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train after smote\n",
      "4515\n",
      "Number of Positive samples after smote\n",
      "2605\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(whiten=True)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_val = pca.transform(X_val)\n",
    "\n",
    "print ('Length of X_train before smote')\n",
    "print (len(X_train))\n",
    "print ('Number of Positives before smote')\n",
    "print (Y_train.sum())\n",
    "\n",
    "\n",
    "print ('Performing Oversampling/Undersampling...')\n",
    "s = SMOTEENN()\n",
    "X_train,Y_train= s.fit_sample(X_train,Y_train)\n",
    "\n",
    "print ('Length of X_train after smote')\n",
    "print (len(X_train))\n",
    "\n",
    "print ('Number of Positive samples after smote')\n",
    "print (Y_train.sum())\n",
    "\n",
    "# print ('Proportion after smote {}'.format(sum(Y_train)/len(Y_train))\n",
    "\n",
    "X_train = X_train.reshape(-1,X_train.shape[1],1)\n",
    "X_test = X_test.reshape(-1,X_test.shape[1],1)\n",
    "X_val = X_val.reshape(-1,X_val.shape[1],1)\n",
    "print ('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite it to be compatiable with Deeplift.\n",
    "\n",
    "There is no MaxoutDense in the Deeplift conversion part, so I skipped them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.regularizers import l1l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import MaxoutDense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling1D\n",
    "\n",
    "def simple_keras_model(original):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(512, 5, border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5),input_shape =(original.shape[1],1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Dropout(.55))\n",
    "    model.add(Convolution1D(512,5,border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Dropout(.55))\n",
    "    model.add(Convolution1D(256,5,border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.55))\n",
    "    model.add(Convolution1D(128,5,border_mode='same',activation='relu',init='he_normal',W_constraint=maxnorm(0.5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.55))\n",
    "    model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Convolution1D(128,3,border_mode='same',activation='relu',init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.35))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    #my_model = Model([original_input], output=output)\n",
    "    optimizer_adam = keras.optimizers.adam(0.001) \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer_adam, metrics=['accuracy'])\n",
    "\n",
    "    return(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4515/4515 [==============================] - 45s - loss: 0.7748 - acc: 0.6660    \n",
      "Epoch 2/20\n",
      "4515/4515 [==============================] - 42s - loss: 0.5313 - acc: 0.7688    \n",
      "Epoch 3/20\n",
      "4515/4515 [==============================] - 45s - loss: 0.3889 - acc: 0.8412    \n",
      "Epoch 4/20\n",
      "4515/4515 [==============================] - 42s - loss: 0.3115 - acc: 0.8711    \n",
      "Epoch 5/20\n",
      "4515/4515 [==============================] - 42s - loss: 0.2485 - acc: 0.9034    \n",
      "Epoch 6/20\n",
      "4515/4515 [==============================] - 42s - loss: 0.1974 - acc: 0.9238    \n",
      "Epoch 7/20\n",
      "4515/4515 [==============================] - 43s - loss: 0.1650 - acc: 0.9367    \n",
      "Epoch 8/20\n",
      "4515/4515 [==============================] - 45s - loss: 0.1559 - acc: 0.9382    \n",
      "Epoch 9/20\n",
      "4515/4515 [==============================] - 47s - loss: 0.1178 - acc: 0.9548    \n",
      "Epoch 10/20\n",
      "4515/4515 [==============================] - 45s - loss: 0.1340 - acc: 0.9499    \n",
      "Epoch 11/20\n",
      "4515/4515 [==============================] - 44s - loss: 0.1140 - acc: 0.9570    \n",
      "Epoch 12/20\n",
      "4515/4515 [==============================] - 54s - loss: 0.1019 - acc: 0.9628    \n",
      "Epoch 13/20\n",
      "4515/4515 [==============================] - 60s - loss: 0.0981 - acc: 0.9617    \n",
      "Epoch 14/20\n",
      "4515/4515 [==============================] - 52s - loss: 0.0888 - acc: 0.9672    \n",
      "Epoch 15/20\n",
      "4515/4515 [==============================] - 53s - loss: 0.0889 - acc: 0.9670    \n",
      "Epoch 16/20\n",
      "4515/4515 [==============================] - 43s - loss: 0.0720 - acc: 0.9745    \n",
      "Epoch 17/20\n",
      "4515/4515 [==============================] - 46s - loss: 0.0674 - acc: 0.9730    \n",
      "Epoch 18/20\n",
      "4515/4515 [==============================] - 46s - loss: 0.0680 - acc: 0.9765    \n",
      "Epoch 19/20\n",
      "4515/4515 [==============================] - 47s - loss: 0.0454 - acc: 0.9845    \n",
      "Epoch 20/20\n",
      "4515/4515 [==============================] - 43s - loss: 0.0656 - acc: 0.9770    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2adda080>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "my_model = simple_keras_model(X_train)\n",
    "my_model.fit(X_train,Y_train,nb_epoch=20,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution1d_1 (Convolution1D)  (None, 18, 512)       3072        convolution1d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 18, 512)       2048        convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 9, 512)        0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 9, 512)        0           maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 9, 512)        1311232     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 9, 512)        2048        convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 4, 512)        0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4, 512)        0           maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 4, 256)        655616      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 4, 256)        1024        convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4, 256)        0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 4, 128)        163968      dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 4, 128)        512         convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4, 128)        0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 4, 128)        49280       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 4, 128)        512         convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 4, 128)        0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_6 (Convolution1D)  (None, 4, 128)        49280       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 4, 128)        512         convolution1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 4, 128)        0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_7 (Convolution1D)  (None, 4, 128)        49280       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 4, 128)        512         convolution1d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 4, 128)        0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_8 (Convolution1D)  (None, 4, 128)        49280       dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 4, 128)        512         convolution1d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 4, 128)        0           batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 512)           0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             513         flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 2,339,201\n",
      "Trainable params: 2,335,361\n",
      "Non-trainable params: 3,840\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeplift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted from the code provided by the authors of the paper [https://arxiv.org/abs/1704.02685]:\n",
    "https://github.com/kundajelab/deeplift/blob/tensorflow/deeplift/conversion/keras_conversion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No reference provided - using zeros\n",
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n"
     ]
    }
   ],
   "source": [
    "#Convert a keras sequential model\n",
    "import deeplift\n",
    "from deeplift.conversion import keras_conversion as kc\n",
    "#MxtsMode defines the method for computing importance scores. Other supported values are:\n",
    "#Gradient, DeconvNet, GuidedBackprop and GuidedBackpropDeepLIFT (a hybrid of GuidedBackprop and DeepLIFT where\n",
    "#negative multipliers are ignored during backpropagation)\n",
    "deeplift_model = kc.convert_sequential_model(\n",
    "                    my_model,\n",
    "                    nonlinear_mxts_mode=deeplift.blobs.NonlinearMxtsMode.DeepLIFT)\n",
    "\n",
    "#Specify the index of the layer to compute the importance scores of.\n",
    "#In the example below, we find scores for the input layer, which is idx 0 in deeplift_model.get_layers()\n",
    "find_scores_layer_idx = 0\n",
    "\n",
    "#Compile the function that computes the importance scores\n",
    "#For sigmoid or softmax outputs, target_layer_idx should be -2 (the default)\n",
    "#(See \"a note on final activation layers\" in https://arxiv.org/pdf/1605.01713v2.pdf for justification)\n",
    "#For regression tasks with a linear output, target_layer_idx should be -1\n",
    "#(which simply refers to the last layer)\n",
    "#FYI: In the case of MxtsMode.DeepLIFT, the importance scores are also called \"contribution scores\"\n",
    "#If you want the multipliers instead of the contribution scores, you can use get_target_multipliers_func\n",
    "deeplift_contribs_func = deeplift_model.get_target_contribs_func(\n",
    "                            find_scores_layer_idx=find_scores_layer_idx,\n",
    "                            target_layer_idx=-2)\n",
    "\n",
    "#compute scores on inputs\n",
    "#input_data_list is a list containing the data for different input layers\n",
    "#eg: for MNIST, there is one input layer with with dimensions 1 x 28 x 28\n",
    "#In the example below, let X be an array with dimension n x 1 x 28 x 28 where n is the number of examples\n",
    "#task_idx represents the index of the node in the output layer that we wish to compute scores.\n",
    "#Eg: if the output is a 10-way softmax, and task_idx is 0, we will compute scores for the first softmax class\n",
    "scores = np.array(deeplift_contribs_func(task_idx=0,\n",
    "                                         input_data_list=[X_train],\n",
    "                                         batch_size=10,\n",
    "                                         progress_update=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = scores.reshape([scores.shape[0],scores.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GoldsteinScale', 'NumMentions', 'avgtone', 'numarticles', 'numsources',\n",
       "       'wit_co', 'unemploy', 'm1v', 'm2v', 'slsi', 'vix', 'dff', 'Open',\n",
       "       'High', 'Low', 'Close', 'Adj Close', 'Volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2bee5c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "data=[s[i] for i in range(18)]\n",
    "plt.boxplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_mean = s.mean(axis=0)\n",
    "mean_df = pd.DataFrame(score_mean).T\n",
    "mean_df.columns = X_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>-1.582610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>-0.933767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>-0.892088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>-0.838652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>-0.434477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>-0.371332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>-0.305149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>-0.267171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>-0.233404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>-0.233038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.132667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>0.154218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>0.406987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>0.414492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj Close</th>\n",
       "      <td>0.422244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>0.451786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>0.462631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>0.862499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "NumMentions    -1.582610\n",
       "wit_co         -0.933767\n",
       "avgtone        -0.892088\n",
       "numarticles    -0.838652\n",
       "numsources     -0.434477\n",
       "m1v            -0.371332\n",
       "vix            -0.305149\n",
       "slsi           -0.267171\n",
       "dff            -0.233404\n",
       "m2v            -0.233038\n",
       "Volume          0.132667\n",
       "High            0.154218\n",
       "Low             0.406987\n",
       "unemploy        0.414492\n",
       "Adj Close       0.422244\n",
       "Close           0.451786\n",
       "GoldsteinScale  0.462631\n",
       "Open            0.862499"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df.T.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.132667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>0.154218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2v</th>\n",
       "      <td>0.233038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dff</th>\n",
       "      <td>0.233404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slsi</th>\n",
       "      <td>0.267171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix</th>\n",
       "      <td>0.305149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1v</th>\n",
       "      <td>0.371332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>0.406987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemploy</th>\n",
       "      <td>0.414492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj Close</th>\n",
       "      <td>0.422244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numsources</th>\n",
       "      <td>0.434477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>0.451786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <td>0.462631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numarticles</th>\n",
       "      <td>0.838652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>0.862499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgtone</th>\n",
       "      <td>0.892088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wit_co</th>\n",
       "      <td>0.933767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumMentions</th>\n",
       "      <td>1.582610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "Volume          0.132667\n",
       "High            0.154218\n",
       "m2v             0.233038\n",
       "dff             0.233404\n",
       "slsi            0.267171\n",
       "vix             0.305149\n",
       "m1v             0.371332\n",
       "Low             0.406987\n",
       "unemploy        0.414492\n",
       "Adj Close       0.422244\n",
       "numsources      0.434477\n",
       "Close           0.451786\n",
       "GoldsteinScale  0.462631\n",
       "numarticles     0.838652\n",
       "Open            0.862499\n",
       "avgtone         0.892088\n",
       "wit_co          0.933767\n",
       "NumMentions     1.582610"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df.abs().T.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that Gdelt features are all somewhat important, especially 'NumMentions', 'avgtone', and 'GoldsteinScale'. In addition, 'Open' and 'wit_co' are fairly more important compared to other finanical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
